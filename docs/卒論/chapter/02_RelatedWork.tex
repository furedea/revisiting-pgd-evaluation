\chapter{関連研究}
本章では本論文で扱うデータセット，及び敵対的攻撃手法について説明する．

\section{データセット}
本研究では，画像分類の代表的なベンチマークデータセットであるMNISTとCIFAR10を使用する．表\ref{table:datasets}に両データセットの概要を示す．

\begin{table}[hbtp]
  \caption{使用するデータセットの概要}
  \label{table:datasets}
  \centering
  \begin{tabular}{l|cc}
    \hline
    項目 & MNIST & CIFAR10 \\
    \hline
    画像サイズ & $28 \times 28 \times 1$ & $32 \times 32 \times 3$ \\
    訓練データ数 & 60,000 & 50,000 \\
    テストデータ数 & 10,000 & 10,000 \\
    ラベル数 & 10 & 10 \\
    内容 & 手書き数字 (0--9) & 物体画像 \\
    \hline
  \end{tabular}
\end{table}

\subsection{MNIST}
MNISTは手書き数字（0から9）の画像データセットであり，機械学習の入門的なベンチマークとして広く用いられている．各画像は$28 \times 28$ピクセルのグレースケール画像であり，ピクセル値は$[0, 1]$に正規化されている．

\subsection{CIFAR10}
CIFAR10は10種類の物体（飛行機，自動車，鳥，猫，鹿，犬，蛙，馬，船，トラック）の画像データセットである\cite{CIFAR10}．各画像は$32 \times 32$ピクセルの3チャネルカラー画像であり，MNISTと比較してより複雑な画像分類タスクを表現している．ラベルと物体の対応は以下の表\ref{table:CIFAR10}の様になっている．

\begin{table}[hbtp]
  \caption{CIFAR10のラベルと物体の対応}
  \label{table:CIFAR10}
  \centering
  \begin{tabular}{cccc}
    ラベル & 物体名 & ラベル & 物体名 \\
    \hline
    0 & airplane   & 5 & dog \\
    1 & automobile & 6 & frog \\
    2 & bird       & 7 & horse \\
    3 & cat        & 8 & ship \\
    4 & deer       & 9 & truck \\
    \hline
  \end{tabular}
\end{table}

\section{PGD攻撃}
\label{sec:pgd}
射影勾配降下法（Projected Gradient Descent; PGD）は，制約付き最適化問題を解くための標準的な反復手法である．Madryらはにおいて，この手法を敵対的サンプルの生成に適用し，PGD攻撃として定式化した\cite{PGD}．PGD攻撃は，制約付き最適化問題を反復的に解くことで，摂動の大きさに制限を設けながらモデルの損失を最大化する敵対的摂動を求める．

\subsection{問題設定}
入力画像を$x \in \mathbb{R}^D$（$D$は入力次元数），正解ラベルを$y$，モデルを$f$，損失関数を$L(x, y)$とする．PGD攻撃は，摂動の$\ell_\infty$ノルムが$\varepsilon$以下という制約のもとで損失を最大化する問題を解く：
\begin{align}
    \max_{\delta} L(x + \delta, y) \quad \text{s.t.} \quad \|\delta\|_\infty \leq \varepsilon
\end{align}
ここで$\varepsilon > 0$は摂動の強さを制御するパラメータである．

\subsection{更新式}
PGD攻撃では以下の更新式を$T$回反復する：
\begin{align}
    x^{t+1}_{\text{adv}} = \Pi_{x + \mathcal{S}} \left( x^t_{\text{adv}} + \alpha \cdot \text{sign}\left( \nabla_{x} L(x^t_{\text{adv}}, y) \right) \right)
    \label{eq:pgd}
\end{align}
ここで，$\alpha$はステップサイズ（$0 < \alpha < \varepsilon$），$\text{sign}(\cdot)$は各成分の符号を取る関数，$\nabla_{x} L$は入力に関する損失の勾配である．また，$\mathcal{S} = \{\delta \in \mathbb{R}^D : \|\delta\|_\infty \leq \varepsilon\}$は許容される摂動の集合であり，$\Pi_{x + \mathcal{S}}(\cdot)$は集合$x + \mathcal{S}$への射影演算子である．

$\ell_\infty$ノルム制約下での射影は成分毎のクリッピングで実現される：
\begin{align}
    \left\{\Pi_{x + \mathcal{S}}(z)\right\}_i = \text{clip}(z_i, x_i - \varepsilon, x_i + \varepsilon)
\end{align}

\subsection{ランダム初期化}
PGD攻撃には初期点$x^0_{\text{adv}}$の設定が必要である．入力点$x$から開始する方法もあるが，ランダム初期化PGDでは制約範囲$x + \mathcal{S}$内の一様乱数点から開始する：
\begin{align}
    x^0_{\text{adv}} = x + u, \quad u \sim \text{Uniform}(-\varepsilon, \varepsilon)^D
\end{align}
ランダム初期化により，複数の異なる初期点から攻撃を行うことで局所最適解への陥りを緩和できる．複数回の試行のうち最も損失が大きくなった敵対的サンプルを採用することが一般的である．

\section{DeepFool}
\label{sec:deepfool}
DeepFoolはMoosavi-Dezfooliらによって提案された敵対的サンプル生成手法であり，$\ell_2$ノルム最小の摂動を求めることを目的としている\cite{DeepFool}．

\subsection{基本原理}
DeepFoolは，ニューラルネットワークを現在の点の近傍で局所的に線形近似し，最も近いラベル境界へ向かう方向に摂動を更新する．分類器が線形であれば，各ラベルの決定境界は超平面で表されるため，境界までの最短摂動を解析的に導出できる．

\subsection{線形近似とラベル境界}
$t$回目の反復における点を$x_t$，モデルのロジット（softmax適用前の出力）を$Z(x) = (Z_1(x), \ldots, Z_K(x))$とする．ここで$K$はラベル数である．現在の予測ラベルを
\begin{align}
    y_t = \arg\max_k Z_k(x_t)
\end{align}
とし，各ラベル$k \neq y_t$について，ロジットスコアの差を
\begin{align}
    g_k(x) = Z_k(x) - Z_{y_t}(x)
\end{align}
と定義する．点$x_t$近傍での一次のテイラー展開により，
\begin{align}
    g_k(x) \approx g_k(x_t) + \nabla g_k(x_t)^\top (x - x_t)
\end{align}
と近似される．

\subsection{最短摂動の導出}
線形近似されたモデルにおいて，ラベル$k$の境界（$g_k(x) = 0$）までの$\ell_2$最短摂動は以下のように導出される：
\begin{align}
    r_{t,k} = -\frac{g_k(x_t)}{\|\nabla g_k(x_t)\|_2^2} \nabla g_k(x_t)
\end{align}
この摂動の$\ell_2$ノルムは
\begin{align}
    \|r_{t,k}\|_2 = \frac{|g_k(x_t)|}{\|\nabla g_k(x_t)\|_2}
\end{align}
である．

\subsection{ターゲットラベルの選択と更新式}
最も境界が近いラベル$k^*$を
\begin{align}
    k^*_t = \arg\min_{k \neq y_t} \|r_{t,k}\|_2
\end{align}
として選択する．実際のニューラルネットワークは非線形であるため，線形近似による境界のずれを考慮し，オーバーシュート係数$\eta > 0$を用いて更新を行う：
\begin{align}
    x_{t+1} = x_t + (1 + \eta) r_{t, k^*_t}
    \label{eq:deepfool}
\end{align}
この更新を，予測ラベルが変化するか，または最大反復回数に達するまで繰り返す．

\section{Madryらの論文における着目実験}
\label{sec:madry_experiment}
Madryらは\cite{PGD}において，PGD攻撃がロバスト性評価に適した手法であることを検証するため，損失の収束に関する実験を行っている．

\subsection{実験概要}
この実験では，ランダム初期化PGD攻撃を複数回（リスタート）実行し，各リスタートにおける反復毎の損失の推移を可視化している．PGD攻撃は制約付き非凸最適化問題を解いているため，初期点によって異なる局所最適解に到達する可能性がある．しかし，異なるランダム初期点から開始しても損失曲線が同程度のプラトー（平坦な領域）に収束するならば，PGD攻撃は安定して同程度の攻撃強度を達成していると解釈できる．

\subsection{実験結果}
Madryらの実験では，MNISTおよびCIFAR10の自然学習モデル（通常の訓練で得られたモデル）と敵対的学習モデル（PGD攻撃による敵対的サンプルを含むデータセットで訓練したモデル）に対してこの検証が行われた．その結果，いずれのモデルにおいても複数のランダム初期点から開始した損失曲線が概ね同程度のプラトーに収束することが示された．

本研究では，この実験の再現を行うとともに，新たな初期化手法を用いた場合の損失の収束挙動について調査する．
