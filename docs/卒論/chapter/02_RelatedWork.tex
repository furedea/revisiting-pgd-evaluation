\chapter{関連研究}

本章では本論文で扱うデータセット，及び敵対的攻撃手法について説明する．

\section{データセット}

本研究では，画像分類の代表的なベンチマークデータセットであるMNISTとCIFAR10を使用する．表\ref{table:datasets}に両データセットの概要を示す．

\begin{table}[hbtp]
  \caption{使用するデータセットの概要}
  \label{table:datasets}
  \centering
  \begin{tabular}{l|cc}
    \hline
    項目 & MNIST & CIFAR10 \\
    \hline
    画像サイズ & $28 \times 28 \times 1$ & $32 \times 32 \times 3$ \\
    訓練データ数 & 60,000 & 50,000 \\
    テストデータ数 & 10,000 & 10,000 \\
    ラベル数 & 10 & 10 \\
    内容 & 手書き数字 (0--9) & 物体画像 \\
    \hline
  \end{tabular}
\end{table}

\subsection{MNIST}

MNISTは手書き数字（0から9）の画像データセットであり，機械学習の入門的なベンチマークとして広く用いられている．各画像は$28 \times 28$ピクセルのグレースケール画像であり，ピクセル値は$[0, 1]$に正規化されている．

\subsection{CIFAR10}

CIFAR10は10種類の物体（飛行機，自動車，鳥，猫，鹿，犬，蛙，馬，船，トラック）の画像データセットである\cite{CIFAR10}．各画像は$32 \times 32$ピクセルの3チャネルカラー画像であり，MNISTと比較してより複雑な画像分類タスクを表現している．ラベルと物体の対応は以下の表\ref{table:CIFAR10}のようになる．

\begin{table}[hbtp]
  \caption{CIFAR10のラベルと物体の対応}
  \label{table:CIFAR10}
  \centering
  \begin{tabular}{cccc}
    ラベル & 物体名 & ラベル & 物体名 \\
    \hline
    0 & airplane   & 5 & dog \\
    1 & automobile & 6 & frog \\
    2 & bird       & 7 & horse \\
    3 & cat        & 8 & ship \\
    4 & deer       & 9 & truck \\
    \hline
  \end{tabular}
\end{table}

\section{PGD攻撃}

\label{sec:pgd}

敵対的サンプル$x_{\text{adv}}$は，入力画像$x$に敵対的摂動$\delta$を加えたものであり，式(\ref{eq:adv_sample})で表される．
\begin{align}
    x_{\text{adv}} = x + \delta
    \label{eq:adv_sample}
\end{align}

Madryらは，制約付き最適化問題を解くための標準的な手法であった射影勾配降下法（Projected Gradient Descent; PGD）をこの敵対的サンプルの生成に適用し，PGD攻撃として定式化した\cite{PGD}．

\subsection{問題設定}

損失関数$L(x, y)$は，モデルの出力$f(x)$と正解ラベル$y$の間の損失を表す．PGD攻撃は，敵対的摂動$\delta$の$\ell_\infty$ノルムが$\varepsilon$以下という制約のもとでこの損失を最大化するような，式(\ref{eq:pgd_objective})で定義される制約付き最適化問題を解く．

\begin{align}
    \max_{\delta} L(x + \delta, y) \quad \text{s.t.} \quad \|\delta\|_\infty \leq \varepsilon
    \label{eq:pgd_objective}
\end{align}

ここで$\varepsilon > 0$は摂動の強さを制御するパラメータであり，$\varepsilon$が大きいほどモデルを誤分類させる力が強くなる．ただし$\varepsilon$が大きすぎると，入力画像と別物と感じられる敵対的サンプルが作られる恐れがあり，同じ入力の小さな改変でモデルが誤分類するかどうかという議論が意味を成さなくなるため注意が必要である．

\subsection{更新式}

PGD攻撃では，以下に示す操作を$T$回反復する．$t$回目の反復における画像$x^t_{adv}$を分類器$f$に入力した場合の損失$L$を計算し，その符号成分のみを取り出す．そして画像$x^t$をその符号成分の方向に学習率$\alpha$の分だけ変化させて$t+1$回目の反復における画像$x^{t+1}_{adv}$を作成する．以上の操作を以下の式(\ref{eq:pgd})で表す．

\begin{align}
    x^{t+1}_{\text{adv}} = \Pi_{x + \mathcal{S}} \left( x^t_{\text{adv}} + \alpha \cdot \text{sign}\left( \nabla_{x} L(x^t_{\text{adv}}, y) \right) \right) \quad (t = 0, 1, \ldots, T-1)
    \label{eq:pgd}
\end{align}

ここで$\text{sign}(\cdot)$は各成分の符号を取る関数であり，$\Pi_{x + \mathcal{S}}(\cdot)$は射影演算子である．$\mathcal{S} = \{\delta \in \mathbb{R}^D : \|\delta\|_\infty \leq \varepsilon\}$は許容される摂動の集合であり，更新後の点が制約範囲$x + \mathcal{S}$を超えた場合，範囲内の最も近い点に射影される．

\subsection{ランダム初期化}
PGD攻撃には初期点$x^0_{\text{adv}}$の設定が必要である．入力点$x$から開始する方法もあるが，ランダム初期化PGDでは，式(\ref{eq:random_init})に示すように，入力画像$x$にランダムな摂動を加えた点から開始する．

\begin{align}
    x^0_{\text{adv}} = x + u, \quad u \sim \text{Uniform}(-\varepsilon, \varepsilon)^D
    \label{eq:random_init}
\end{align}

ここで$D$は入力画像の次元数である．この初期点から式(\ref{eq:pgd})の更新を$T$回繰り返し，最終的に得られる$x^T_{\text{adv}}$が敵対的サンプルとなる．

ランダム初期化により初期点が異なると到達する局所最適解も異なる可能性があるため，一つの入力画像に対して複数の異なる初期点から攻撃を行い，最も損失が大きくなった敵対的サンプルを採用することが一般的である．この複数回の試行をリスタートと呼ぶ．

\section{DeepFool}
\label{sec:deepfool}
DeepFool\cite{DeepFool}はMoosavi-Dezfooliらによって提案された敵対的攻撃手法であり，$\ell_2$ノルム最小の摂動を求めることを目的としている．

\subsection{基本原理}

DeepFoolは，ニューラルネットワークを現在の点の近傍で局所的に線形近似し，最も近いラベル境界へ向かう方向に摂動を更新する．分類器が線形であれば，各ラベルの決定境界は超平面で表されるため，境界までの最短摂動を解析的に導出できる．

\subsection{線形近似とラベル境界}
$t$回目の反復における点を$x_t$，モデルのロジット（活性化関数適用前の出力）を$Z(x) = (Z_1(x), \ldots, Z_K(x))$とする．ここで$K$はラベル数である．現在の予測ラベルを
\begin{align}
    y_t = \arg\max_k Z_k(x_t)
\end{align}
とし，各ラベル$k \neq y_t$について，ロジットのスコアの差を
\begin{align}
    g_k(x) = Z_k(x) - Z_{y_t}(x)
\end{align}
と定義する．点$x_t$近傍での一次のテイラー展開により，
\begin{align}
    g_k(x) \approx g_k(x_t) + \nabla g_k(x_t)^\top (x - x_t)
\end{align}
と近似される．

\subsection{最短摂動の導出}
線形近似されたモデルにおいて，ラベル$k$の境界（$g_k(x) = 0$）までの$\ell_2$最短摂動は以下のように導出される：
\begin{align}
    r_{t,k} = -\frac{g_k(x_t)}{\|\nabla g_k(x_t)\|_2^2} \nabla g_k(x_t)
\end{align}
この摂動の$\ell_2$ノルムは
\begin{align}
    \|r_{t,k}\|_2 = \frac{|g_k(x_t)|}{\|\nabla g_k(x_t)\|_2}
\end{align}
である．

\subsection{ターゲットラベルの選択と更新式}
最も境界が近いラベル$k^*$を
\begin{align}
    k^*_t = \arg\min_{k \neq y_t} \|r_{t,k}\|_2
\end{align}
として選択する．実際のニューラルネットワークは非線形であるため，線形近似による境界のずれを考慮し，オーバーシュート係数$\eta > 0$を用いて更新を行う：
\begin{align}
    x_{t+1} = x_t + (1 + \eta) r_{t, k^*_t}
    \label{eq:deepfool}
\end{align}
この更新を，予測ラベルが変化するか，または最大反復回数に達するまで繰り返す．

\section{Madryらの論文における着目実験}
\label{sec:madry_experiment}
Madryらは\cite{PGD}において，PGD攻撃がロバスト性評価に適した手法であることを検証するため，損失の収束に関する実験を行っている．

\subsection{実験概要}
この実験では，ランダム初期化PGD攻撃を複数回（リスタート）実行し，各リスタートにおける反復毎の損失の推移を可視化している．PGD攻撃は制約付き非凸最適化問題を解いているため，初期点によって異なる局所最適解に到達する可能性がある．しかし，異なるランダム初期点から開始しても損失曲線が同程度のプラトー（平坦な領域）に収束するならば，PGD攻撃は安定して同程度の攻撃強度を達成していると解釈できる．

\subsection{実験結果}
Madryらの実験では，MNISTおよびCIFAR10の自然学習モデル（通常の訓練で得られたモデル）と敵対的学習モデル（PGD攻撃による敵対的サンプルを含むデータセットで訓練したモデル）に対してこの検証が行われた．その結果，いずれのモデルにおいても複数のランダム初期点から開始した損失曲線が概ね同程度のプラトーに収束することが示された．

本研究では，この実験の再現を行うとともに，新たな初期化手法を用いた場合の損失の収束挙動について調査する．
