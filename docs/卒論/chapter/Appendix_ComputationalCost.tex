\appendix

\chapter{実行時間の計測}
\label{appendix:computational_cost}

本付録では，各初期化手法の実行時間を計測し，計算コストの実測値を比較する．

\section{計測方法}
\label{sec:timing_methodology}

\subsection{計測対象}

実行時間の計測は，初期化手法の比較を目的とする．公平な比較のため，以下の2つのグループに分けて計測を行う：
\begin{itemize}
    \item \textbf{1リスタート比較}: ランダム初期化（リスタート数1）とDeepFool初期化（リスタート数1）
    \item \textbf{9リスタート比較}: ランダム初期化（リスタート数9）とMulti-DeepFool初期化（リスタート数9）
\end{itemize}

\subsection{計測の構成}

1サンプルに対する攻撃の実行時間を，以下の2つに分けて計測する：
\begin{enumerate}
    \item \textbf{初期点生成}: PGD攻撃の初期点$x^0$を生成する処理．ランダム初期化では一様乱数の生成，DeepFool初期化およびMulti-DeepFool初期化ではDeepFoolアルゴリズムの実行が含まれる．
    \item \textbf{PGD反復}: 初期点$x^0$から$T$回の反復更新（式(\ref{eq:pgd})）を実行する処理．
\end{enumerate}

\subsection{計測に含まれる処理}

上記の各計測には，以下の処理が含まれる：

\paragraph{初期点生成}
\begin{itemize}
    \item 乱数の生成（ランダム初期化の場合）
    \item DeepFoolアルゴリズムの反復計算（DeepFool初期化，Multi-DeepFool初期化の場合）
    \item $\ell_\infty$制約範囲への射影（第\ref{sec:deepfool_init}節，式(\ref{eq:clip})）
    \item 画素値の$[0, 1]$範囲への制限
\end{itemize}

\paragraph{PGD攻撃}
\begin{itemize}
    \item 勾配$\nabla_x L(x^t, y)$の計算
    \item 符号関数$\text{sign}(\cdot)$の適用と摂動の加算
    \item $\ell_\infty$制約範囲への射影（式(\ref{eq:pgd})における$\text{Clip}_\varepsilon(\cdot)$）
\end{itemize}

これらの処理は初期化手法およびPGD攻撃の本質的な部分であり，計測に含めることが適切である．

\subsection{計測から除外される処理}

以下の処理は計測から除外される：
\begin{itemize}
    \item \textbf{バッチの構成}: 入力画像およびラベルをリスタート数分複製する処理．全ての初期化手法で共通であり，比較に影響しない．
    \item \textbf{モデルの読み込み}: ニューラルネットワークの構築およびパラメータの復元．攻撃実行前の前処理である．
    \item \textbf{データの読み込み}: テストデータセットの読み込み．
    \item \textbf{結果の保存}: 計測結果のファイルへの書き込み．
\end{itemize}

\subsection{計測の実装}

実行時間の計測にはPythonの\texttt{time.perf\_counter()}関数を使用した．この関数はオペレーティングシステムが提供する高精度タイマーを利用しており，短時間の処理の計測に適している．

\subsection{ウォームアップ}

TensorFlowでは，最初の実行時に計算グラフのコンパイルやGPUメモリの確保が行われ，通常より長い実行時間を要する．このオーバーヘッドを除外するため，本計測の前に同一の処理を1回実行し，その結果は破棄する．

\subsection{並列実行について}

本計測はGPU上で実行されるため，TensorFlowの内部で並列実行が行われる可能性がある．並列実行の有無や程度を完全に制御することは困難であるが，同一の実行環境において各手法を順次実行するため，並列実行の影響は全ての手法に対して同等に作用すると考えられる．したがって，手法間の相対的な比較においては妥当な計測となる．

\subsection{計測値の単位}

計測値は，指定されたリスタート数の全試行に対する合計時間とする．例えば，リスタート数9の場合は9回分の初期点生成と9回分のPGD反復の合計時間を計測する．

リスタートあたりの平均時間を用いない理由は，バッチ処理による並列実行の効果が含まれるためである．GPUではバッチサイズが大きいほど並列処理の効率が向上する傾向があり，リスタートあたりの実行時間はバッチサイズに依存する．この効果は初期化手法の本質的な計算コストとは無関係であるため，合計時間を用いて比較を行う．

\section{計測結果}
\label{sec:timing_results}

% TODO: 計測結果を記載

\subsection{MNIST}

表\ref{table:mnist_timing}にMNISTにおける実行時間の計測結果を示す．

\begin{table}[H]
    \caption{MNISTにおける実行時間比較}
    \label{table:mnist_timing}
    \centering
    \small
    \begin{tabular}{c|l|ccc|c}
        \hline
        リスタート数 & 初期化手法 & 初期点生成 (s) & PGD反復 (s) & 合計 (s) & 比率 \\
        \hline
        \multirow{2}{*}{1} & ランダム & --- & --- & --- & 1.00 \\
         & DeepFool & --- & --- & --- & --- \\
        \hline
        \multirow{2}{*}{9} & ランダム & --- & --- & --- & 1.00 \\
         & Multi-DeepFool & --- & --- & --- & --- \\
        \hline
    \end{tabular}
\end{table}

% TODO: 結果の考察を記載

\subsection{CIFAR10}

表\ref{table:cifar10_timing}にCIFAR10における実行時間の計測結果を示す．

\begin{table}[H]
    \caption{CIFAR10における実行時間比較}
    \label{table:cifar10_timing}
    \centering
    \small
    \begin{tabular}{c|l|ccc|c}
        \hline
        リスタート数 & 初期化手法 & 初期点生成 (s) & PGD反復 (s) & 合計 (s) & 比率 \\
        \hline
        \multirow{2}{*}{1} & ランダム & --- & --- & --- & 1.00 \\
         & DeepFool & --- & --- & --- & --- \\
        \hline
        \multirow{2}{*}{9} & ランダム & --- & --- & --- & 1.00 \\
         & Multi-DeepFool & --- & --- & --- & --- \\
        \hline
    \end{tabular}
\end{table}

% TODO: 結果の考察を記載

\section{考察}
\label{sec:timing_discussion}

% TODO: 実験結果に基づいて考察を記載
