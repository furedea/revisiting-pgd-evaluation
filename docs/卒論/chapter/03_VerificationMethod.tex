\chapter{検証方法}
本章では，PGD攻撃の収束性を定量的に評価するための検証方法について述べる．

\section{本研究における検証の目的}
\label{sec:verification_purpose}

Madryらは\cite{PGD}において，PGD攻撃の損失曲線が複数のランダム初期点から開始しても同程度のプラトーに収束することを可視化により示した．しかし，この検証は定性的なものであり，具体的にどの反復回数で収束が起こるか，あるいは収束の速さがモデルや初期化手法によってどのように異なるかについては詳細に論じられていない．

本研究では，Madryらの実験を定量的に拡張し，以下の観点から検証を行う：
\begin{itemize}
    \item 損失曲線が収束に達するまでの反復回数の統計的分布
    \item 異なるモデル（自然学習・敵対的学習）間での収束挙動の比較
    \item 異なる初期化手法が収束速度に与える影響
\end{itemize}

\section{収束の定義}
\label{sec:convergence_definition}

PGD攻撃の収束を定量的に評価するために，正規化損失収束率と収束閾値を定義する．

\subsection{正規化損失収束率の定義}
\label{sec:normalized_loss_convergence_ratio}

異なるサンプル間で損失の収束度合いを比較可能にするため，本研究では\textbf{正規化損失収束率}（normalized loss convergence ratio）を以下のように定義する．反復$t$における損失を$L_t$，初期損失を$L_0$，最終損失を$L_{\max}$とすると，正規化損失収束率$\rho_t$は以下のように定義される：
\begin{align}
    \rho_t = \frac{L_t - L_0}{L_{\max} - L_0}
    \label{eq:normalized_loss_convergence_ratio}
\end{align}

この正規化により，$\rho_0 = 0$（初期時点），$\rho_T = 1$（最終時点）となり，異なるサンプル間で損失の収束度合いを統一的に評価できる．

\subsection{収束閾値}
\label{sec:convergence_threshold}

収束閾値$\theta \in (0, 1)$を用いて，正規化損失収束率が初めて閾値に達した反復回数を収束反復数と定義する．すなわち，収束反復数$t^*$は以下のように定義される：
\begin{align}
    t^* = \min\{t : \rho_t \geq \theta\}
    \label{eq:convergence_iteration}
\end{align}

本研究では，収束閾値として$\theta = 0.90$を採用する．これは，最終損失の90\%に到達した時点を収束とみなすことを意味する．この閾値は，損失曲線がプラトーに入る直前の段階を捉えるものとして選択した．

\section{評価指標}
\label{sec:evaluation_metrics}

収束の定量的評価のため，以下の指標を用いる．

\subsection{収束率}
\label{sec:convergence_rate}

収束率は，与えられた反復回数内で収束閾値に到達したサンプルの割合を表す．全サンプル数を$N$，反復回数$T$以内に収束したサンプル数を$N_c$とすると，収束率$R_c$は以下のように定義される：
\begin{align}
    R_c = \frac{N_c}{N}
    \label{eq:convergence_rate}
\end{align}

本研究では最大反復回数$T = 100$を設定しているため，$R_c = 1.0$であれば全サンプルが100反復以内に収束閾値に到達したことを意味する．

\subsection{収束反復数の統計量}
\label{sec:convergence_statistics}

収束反復数の分布を特徴づけるため，以下の統計量を計算する：
\begin{itemize}
    \item 平均収束反復数：収束反復数の算術平均
    \item 中央値（Median）：収束反復数の中央値
    \item 95パーセンタイル（P95）：収束反復数の分布において95\%のサンプルが収束に到達する反復回数
\end{itemize}

特にP95は，ほぼ全てのサンプルが収束に到達するために必要な反復回数の目安として重要である．

\subsection{累積分布関数（CDF）}
\label{sec:cdf}

収束反復数の累積分布関数（Cumulative Distribution Function; CDF）は，ある反復回数$t$までに収束したサンプルの割合を表す：
\begin{align}
    F(t) = \frac{|\{i : t^*_i \leq t\}|}{N}
    \label{eq:cdf}
\end{align}

CDFを可視化することで，収束速度の分布を直感的に把握できる．CDFが急激に立ち上がる場合は多くのサンプルが短い反復回数で収束していることを示し，緩やかに立ち上がる場合は収束に要する反復回数のばらつきが大きいことを示す．

\section{検証対象のモデル}
\label{sec:target_models}

本研究では，Madryらが公開しているリポジトリ\cite{MadryMNIST, MadryCIFAR10}から入手した以下の4種類のモデルを使用する．

\begin{table}[hbtp]
  \caption{検証対象のモデル}
  \label{table:models}
  \centering
  \begin{tabular}{l|l|l}
    \hline
    モデル名 & 訓練方法 & 説明 \\
    \hline
    nat & 自然学習 & 通常のクリーンデータのみで訓練 \\
    adv & 敵対的学習 & PGD敵対的サンプルを含むデータで訓練 \\
    nat\_and\_adv & 混合学習 & クリーンデータとPGD敵対的サンプルの両方で訓練 \\
    weak\_adv & 弱敵対的学習 & 弱いPGD攻撃（少ない反復回数）で訓練 \\
    \hline
  \end{tabular}
\end{table}

自然学習モデル（nat）は敵対的摂動に対して脆弱であり，PGD攻撃により高い損失に到達しやすい．一方，敵対的学習モデル（adv）は敵対的摂動に対して堅牢であり，損失の増加が抑制される傾向がある．これらのモデル間での収束挙動の違いを比較することで，モデルのロバスト性と収束特性の関係を調査する．
