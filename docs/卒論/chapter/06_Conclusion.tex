\chapter{結論}

\section{本研究の成果}

本研究では，PGD攻撃によるロバスト性評価の信頼性について，反復数と初期化手法の観点から再検証を行った．

\subsection{PGD攻撃の誤分類性能の検証}
Madryらが報告したPGD攻撃の損失収束に関する実験の再現を行い，誤分類に基づく定量的な評価指標を用いて拡張した．誤分類達成反復数を用いた評価により，PGD攻撃の誤分類特性がモデルやデータセットによって大きく異なることを確認した．

主な知見として以下が得られた：
\begin{itemize}
    \item 異なるランダム初期点から開始しても，損失曲線は同程度の局所最大値に収束する（Madryらの報告と一致）．
    \item MNISTでは，advモデルのみが100反復のPGD攻撃に対して堅牢であり，全ての初期化手法で誤分類達成率0\%であった．
    \item CIFAR10では，全てのモデルで35\%以上の誤分類達成率を示し，MNISTと比較して敵対的訓練の効果が限定的であった．
    \item CIFAR10はMNISTと比較して桁違いに高速な誤分類が観察された（natモデルのランダム初期化でMNISTの場合平均5.4反復，CIFAR10の場合平均1.2反復）．
\end{itemize}

\subsection{DeepFool初期化およびMulti-DeepFool初期化手法の提案と評価}
PGD攻撃の新たな初期化手法として，DeepFoolの境界情報を用いたDeepFool初期化およびMulti-DeepFool初期化を提案し，その効果を検証した．

主な知見として以下が得られた：
\begin{itemize}
    \item 脆弱なモデル（nat, weak\_adv）に対しては，DeepFool初期化およびMulti-DeepFool初期化によりランダム初期化よりも少ない反復で誤分類を達成可能
    \item 堅牢なモデル（MNIST adv）に対しては，どの初期化手法を用いても100反復以内に誤分類を達成できない
    \item DeepFool初期化およびMulti-DeepFool初期化の効果は，$\ell_\infty$制約内で決定境界を超えられるかどうかに依存する
    \item DeepFool初期化は最も近い決定境界への方向のみを使用するのに対し，Multi-DeepFool初期化は全てのターゲットラベルへの境界を探索することで約ラベル数分の多様な探索が可能である
    \item Multi-DeepFool初期化はDeepFool初期化と比較して平均反復数がやや多い傾向がある（MNISTのnatモデルでDeepFool初期化は平均0.0反復，Multi-DeepFool初期化は平均0.5反復）
\end{itemize}

\subsection{その他の実験的知見}
本研究を通じて，以下の実験的知見が得られた：
\begin{itemize}
    \item MNISTのnatモデルでは，ランダム初期化で平均5.4反復，DeepFool初期化で平均0.0反復で誤分類する．
    \item CIFAR10のnatモデルでは，ランダム初期化で平均1.2反復，DeepFool初期化で平均0.0反復で誤分類する．
    \item 敵対的訓練の効果はデータセットによって異なり，MNISTではadvモデルのみが堅牢（誤分類達成率0\%）だが，CIFAR10では全モデルで35\%以上の誤分類達成率を示した
    \item 高次元データ（CIFAR10）では誤分類が非常に高速に達成されるため，攻撃の成否（攻撃成功率）が重要な指標となる
\end{itemize}

\section{今後の展望}

本研究を発展させる方向として，以下の課題が考えられる．

\begin{itemize}
    \item \textbf{他のデータセット・モデルへの適用}：ImageNetなどのより大規模なデータセットや，異なるアーキテクチャのモデルへの適用可能性を検証する
    \item \textbf{他の攻撃手法との比較}：AutoAttackやCW攻撃など，他の強力な攻撃手法との誤分類達成反復数の比較を行う
    \item \textbf{堅牢なモデルへの攻撃}：100反復で誤分類を達成できなかったモデル（MNIST adv）に対し，より長い反復数や他の攻撃手法を用いた検証を行う
    \item \textbf{制約適用による損失低下の改善}：DeepFool初期化の制約適用による誤分類成功率低下を改善する手法の検討
    \item \textbf{計算効率の改善}：DeepFool初期化の計算コストを削減しつつ，誤分類高速化の効果を維持する手法の検討
\end{itemize}
