\chapter{結論}

\section{本研究の成果}

本研究では，PGD攻撃によるロバスト性評価の信頼性について，反復数と初期化手法の観点から再検証を行った．

\subsection{PGD攻撃の誤分類速度検証}
Madryらが報告したPGD攻撃の損失収束に関する実験の再現を行い，誤分類に基づく定量的な評価指標を用いて拡張した．最初の誤分類反復数を用いた評価により，PGD攻撃の誤分類特性がモデルやデータセットによって大きく異なることを確認した．

主な知見として以下が得られた：
\begin{itemize}
    \item 異なるランダム初期点から開始しても，損失曲線は同程度のプラトーに収束する（Madryらの報告と一致）
    \item MNISTでは，advモデルとnat\_and\_advモデルは100反復のPGD攻撃に対して堅牢であり，全ての初期化手法で攻撃成功率0\%であった
    \item CIFAR10では，advモデルのみが100反復のPGD攻撃に対して堅牢であり，他の3モデルは2反復以内に誤分類を達成した
    \item CIFAR10はMNISTと比較して桁違いに高速な誤分類が観察された（natモデルでMNIST平均6.6反復 vs CIFAR10平均1.3反復）
\end{itemize}

\subsection{DeepFool初期化手法の提案と評価}
PGD攻撃の新たな初期化手法として，DeepFoolの境界情報を用いた初期化を提案し，その効果を検証した．

主な知見として以下が得られた：
\begin{itemize}
    \item 脆弱なモデル（nat, weak\_adv）に対しては，DeepFool初期化によりランダム初期化よりも少ない反復で誤分類を達成可能
    \item 堅牢なモデル（adv, MNIST nat\_and\_adv）に対しては，どの初期化手法を用いても100反復以内に誤分類を達成できない
    \item DeepFool初期化の効果は，$\ell_\infty$制約内で決定境界を超えられるかどうかに依存する
\end{itemize}

\subsection{実験的知見}
本研究を通じて，以下の実験的知見が得られた：
\begin{itemize}
    \item MNISTのnatモデルでは，ランダム初期化で平均6.6反復，DeepFool初期化で平均0反復で誤分類を達成
    \item CIFAR10のnatモデルでは，ランダム初期化で平均1.3反復，DeepFool初期化で平均0反復で誤分類を達成
    \item 敵対的訓練の効果はデータセットによって異なり，MNISTではnat\_and\_advモデルも堅牢だが，CIFAR10では脆弱
    \item 高次元データ（CIFAR10）では誤分類が非常に高速に達成されるため，攻撃の成否（攻撃成功率）が重要な指標となる
\end{itemize}

\section{今後の展望}

本研究を発展させる方向として，以下の課題が考えられる．

\begin{itemize}
    \item \textbf{他のデータセット・モデルへの適用}：ImageNetなどのより大規模なデータセットや，異なるアーキテクチャのモデルへの適用可能性を検証する
    \item \textbf{他の攻撃手法との比較}：AutoAttackやCW攻撃など，他の強力な攻撃手法との誤分類速度比較を行う
    \item \textbf{堅牢なモデルへの攻撃}：100反復で誤分類を達成できなかったモデル（MNIST adv, nat\_and\_adv，CIFAR10 adv）に対して，より長い反復数や他の攻撃手法を用いた検証を行う
    \item \textbf{制約適用による損失低下の改善}：DeepFool初期化の制約適用による誤分類成功率低下を改善する手法の検討
    \item \textbf{計算効率の改善}：DeepFool初期化の計算コストを削減しつつ，誤分類高速化の効果を維持する手法の検討
\end{itemize}
