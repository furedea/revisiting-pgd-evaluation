\chapter{評価実験}
\label{chapter:experiment}
本章では，第\ref{chapter:introduction}章で述べた目的に基づき，第\ref{chapter:evaluation_method}章で定義した評価指標を用いて，PGD攻撃の誤分類速度を実験的に評価する．

\section{実験対象}
\label{sec:experiment_target}

本節では，本研究で使用するデータセット，初期化手法，およびモデルについて説明する．

\subsection{データセット}
\label{sec:datasets}

本研究では，画像分類の代表的なベンチマークデータセットであるMNISTとCIFAR10を使用する．これらはMadryらの実験\cite{PGD}で使用されたデータセットであり，実験の再現性を確保するために同じデータセットを採用した．表\ref{table:datasets}に両データセットの概要を示す．

\begin{table}[hbtp]
  \caption{使用するデータセットの概要}
  \label{table:datasets}
  \centering
  \begin{tabular}{l|cc}
    \hline
    項目 & MNIST & CIFAR10 \\
    \hline
    画像サイズ & $28 \times 28 \times 1$ & $32 \times 32 \times 3$ \\
    訓練データ数 & 60,000 & 50,000 \\
    テストデータ数 & 10,000 & 10,000 \\
    ラベル数 & 10 & 10 \\
    内容 & 手書き数字 (0--9) & 物体画像 \\
    \hline
  \end{tabular}
\end{table}

MNISTは手書き数字（0から9）の画像データセットであり，機械学習の入門的なベンチマークとして広く用いられている．各画像は$28 \times 28$ピクセルのグレースケール画像であり，ピクセル値は$[0, 1]$に正規化されている．

CIFAR10は10種類の物体（飛行機，自動車，鳥，猫，鹿，犬，蛙，馬，船，トラック）の画像データセットである\cite{CIFAR10}．各画像は$32 \times 32$ピクセルの3チャネルカラー画像であり，MNISTと比較してより複雑な画像分類タスクを表現している．ラベルと物体の対応は以下の表\ref{table:CIFAR10}のようになる．

\begin{table}[hbtp]
  \caption{CIFAR10のラベルと物体の対応}
  \label{table:CIFAR10}
  \centering
  \begin{tabular}{cccc}
    ラベル & 物体名 & ラベル & 物体名 \\
    \hline
    0 & airplane   & 5 & dog \\
    1 & automobile & 6 & frog \\
    2 & bird       & 7 & horse \\
    3 & cat        & 8 & ship \\
    4 & deer       & 9 & truck \\
    \hline
  \end{tabular}
\end{table}

\subsection{モデル}
\label{sec:target_models}

表\ref{table:models}に使用するモデルの詳細を示す．natおよびadvモデルは，Madryらが公開しているリポジトリ\cite{MadryMNIST, MadryCIFAR10}から入手した事前学習済みモデルである．ただし，advモデルはPGD攻撃に対して極めて頑強であり，100反復以内に誤分類が達成されなかったため，誤分類速度の評価が困難であった．そこで，natとadvの中間的なロバスト性を持つと期待されるnat\_and\_advおよびweak\_advモデルを，同リポジトリのtrain.pyを修正して追加で学習させた．

\begin{table}[hbtp]
  \caption{実験対象のモデル}
  \label{table:models}
  \centering
  \begin{tabular}{l|p{10cm}}
    \hline
    モデル名 & 訓練データ \\
    \hline
    nat & クリーンデータのみ \\
    adv & PGD敵対的サンプルのみ \\
    nat\_and\_adv & クリーンデータ50\%とPGD敵対的サンプル50\% \\
    weak\_adv & $\varepsilon$を半分にしたPGD敵対的サンプルのみ \\
    \hline
  \end{tabular}
\end{table}

各モデルの特性と，本研究での実験における意義は以下の通りである：
\begin{itemize}
    \item \textbf{nat（自然学習モデル）}：クリーンデータのみで訓練されたモデル．敵対的摂動に対して脆弱であり，PGD攻撃により高い損失に到達しやすい．誤分類が最も容易と予想され，ベースラインとして機能する．
    \item \textbf{adv（敵対的学習モデル）}：PGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．敵対的摂動に対して堅牢であり，損失の増加が抑制される傾向がある．誤分類が困難になる可能性があり，初期化手法の効果が顕著に現れると予想される．
    \item \textbf{nat\_and\_adv}：クリーンデータ50\%とPGD敵対的サンプル50\%を混合して訓練されたモデル．自然精度と敵対的精度の両立を目指した訓練方法であり，natとadvの中間的な特性を持つと予想される．
    \item \textbf{weak\_adv}：摂動制約$\varepsilon$を標準設定の半分にした弱いPGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．弱い攻撃に対しては堅牢だが，標準的な強さの攻撃に対する堅牢性は限定的．advよりは誤分類しやすいが，natよりは困難と予想される．
\end{itemize}

これらのモデル間での誤分類挙動の違いを比較することで，モデルのロバスト性と誤分類速度の関係を調査する．

\subsection{初期化手法}
\label{sec:init_methods}

PGD攻撃の初期点の選び方として，本研究では以下の初期化手法を比較する：
\begin{itemize}
    \item \textbf{クリーン初期化}：元の入力画像$x$をそのまま初期点として使用する．最も単純な初期化手法である．
    \item \textbf{ランダム初期化}：入力画像$x$を中心とする$\ell_\infty$制約範囲内から一様乱数で初期点を選択する．Madryらの論文\cite{PGD}で用いられた標準的な手法であり，ベースラインとして機能する．乱数シードを固定しており，実験の再現性が保証される．
    \item \textbf{DeepFool初期化}：DeepFoolで生成した敵対的サンプルを初期点とする．
    \item \textbf{Multi-DeepFool初期化}：各ターゲットラベルへのDeepFool結果を初期点とする．
\end{itemize}

ランダム初期化の詳細は第\ref{sec:random_init}節，DeepFool初期化およびMulti-DeepFool初期化の詳細は第\ref{chapter:proposed}章を参照されたい．

\section{実験設定}
\label{sec:experiment_setting}

\subsection{攻撃パラメータ}
表\ref{table:attack_params}にPGD攻撃のパラメータを示す．これらのパラメータはMadryらの論文\cite{PGD}と同一の設定である．DeepFoolのパラメータは，最大反復回数$T_{\text{df}} = 50$，オーバーシュート係数$\eta = 0.02$とする．

\begin{table}[hbtp]
  \caption{PGD攻撃のパラメータ設定}
  \label{table:attack_params}
  \centering
  \begin{tabular}{l|cc}
    \hline
    パラメータ & MNIST & CIFAR10 \\
    \hline
    摂動制約$\varepsilon$ & $0.3$ & $8/255 \approx 0.031$ \\
    ステップサイズ$\alpha$ & $0.01$ & $2/255 \approx 0.008$ \\
    反復数$T$ & $100$ & $100$ \\
    \hline
  \end{tabular}
\end{table}

\subsection{リスタート数}
表\ref{table:restart_per_init}に初期化手法ごとのリスタート数を示す．決定的な初期化手法（クリーン，DeepFool）はリスタート数1，確率的なランダム初期化はリスタート数20として実験を行う．ランダム初期化のリスタート数はMadryらの論文\cite{PGD}と同一の設定である．Multi-DeepFool初期化は9つのターゲットクラスに対して独立にPGD攻撃を実行するため，リスタート数を9として扱う．

\begin{table}[hbtp]
  \caption{初期化手法ごとのリスタート数}
  \label{table:restart_per_init}
  \centering
  \begin{tabular}{l|c|l}
    \hline
    初期化手法 & リスタート数 & 性質 \\
    \hline
    クリーン & 1 & 決定的 \\
    ランダム & 20 & 確率的 \\
    DeepFool & 1 & 決定的 \\
    Multi-DeepFool & 9 & 決定的 \\
    \hline
  \end{tabular}
\end{table}

\subsection{テストサンプルの選択}

\label{sec:sample_selection}

テストデータの取得にはTensorFlowの標準データローダーを使用した．MNISTはTensorFlow 1.x系に付属するMNISTデータローダー，CIFAR10はKerasのデータセットAPIからそれぞれ取得した．これらのローダーが返すテストデータの順序は固定されており，再現性が保証される．

実験に使用するテストサンプルは，各データセットのテストデータから以下の手順で選択した：

\begin{enumerate}
    \item テストデータを先頭から順に走査
    \item 対象モデルが自然画像の状態で正しく分類するサンプルを抽出
    \item 最初に見つかった5枚（または1枚）を評価用サンプルとして使用
\end{enumerate}

この選択基準は，PGD攻撃の前提条件である「元々正しく分類されているサンプルに対する攻撃」を満たすためである．攻撃前から誤分類されているサンプルを評価対象に含めると，攻撃の効果を正しく評価できない．

なお，上記の選択基準により，モデルが異なれば選択されるサンプルも異なる場合がある．例えば，あるモデルがテストデータの先頭のサンプルを誤分類する場合，そのモデルの評価では先頭のサンプルは使用されず2番目以降のサンプルから選択される．異なるモデル間の比較を行う際には，この点に留意し同じサンプル同士で比較する必要がある．

\subsection{実行環境}
実験はPython 3.6.9およびTensorFlow 1.15.5を用いて実施した．Madryらが公開しているモデルおよび学習コードはTensorFlow 1.x系で実装されており，これらを正常に動作させるために環境を合わせた．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{損失曲線の観察}
\label{sec:loss_curve_observation}

本節では，各初期化手法によるPGD攻撃の損失曲線を可視化し，攻撃の挙動を定性的に観察する．これはMadryらの実験の再現及び拡張に相当する．

本節の図は行ごとに全て以下の3段構成となっている．また各列は，節\ref{sec:sample_selection}に基づき選択された，異なる5つのテストサンプルに対応している．

\paragraph{損失曲線（上段）}
縦軸は交差エントロピー損失（Cross-entropy Loss），横軸はPGD攻撃の反復回数（PGD Iterations）を表す．反復0は初期状態に対応する．曲線が上昇するほど攻撃が進行（モデルの予測確信度が低下）していることを意味する．Multi-DeepFool初期化の図では，各曲線の色が境界までの距離の順位を表す．暖色（赤）はより近い境界へ向かった試行，寒色（青）はより遠い境界へ向かった試行を意味する．

\paragraph{正誤ヒートマップ（中段）}
縦軸はリスタート番号，横軸は反復回数を表す．各セルの色は，その時点での敵対的サンプルに対するモデルの予測結果を示す．黄色は正しく分類（攻撃失敗），紫色は誤分類（攻撃成功）を意味する．このヒートマップにより，各リスタートがいつ攻撃に成功したかを視覚的に確認できる．

\paragraph{画像比較（下段）}
左側の\texttt{x\_nat}は元の自然画像（摂動を加える前の入力），右側の\texttt{x\_adv}はPGD攻撃により生成された敵対的サンプルを示す．DeepFool初期化およびMulti-DeepFool初期化の図では，中央に\texttt{x\_df}としてDeepFoolで生成した敵対的サンプル（$\ell_\infty$制約適用前）も表示する．

\subsection{ランダム初期化}
\label{sec:random_loss_curves}

本節では，Madryらの実験の再現及び拡張として，各モデルに対するランダム初期化PGD攻撃の損失曲線と正誤ヒートマップを可視化する．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_random}にMNIST natモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_random_indices0-1-2-3-4_k100_eps0.3_a0.01_r20_seed0.png}
  \caption{MNIST natモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像とPGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_random}
\end{figure}

\medskip
図\ref{fig:mnist_nat_random}より，以下の観察が得られる．20回のリスタートは異なるランダム初期点から開始しているが，いずれも同程度のプラトーに収束している．これはMadryらの「異なる初期点から同程度の局所最大解に収束する」という観察と一致する．損失曲線を詳細に見ると，初期の数反復で急速に損失が上昇し，その後は緩やかな上昇に転じている．

ヒートマップを見ると，多くのリスタートが5〜15反復程度で攻撃成功（紫色）に至っており，初期点やサンプルに依らず安定した攻撃が行われていることがわかる．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_random}にMNIST advモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_random_indices0-1-2-3-4_k100_eps0.3_a0.01_r20_seed0.png}
  \caption{MNIST advモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像とPGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_random}
\end{figure}

\medskip
図\ref{fig:mnist_adv_random}より，advモデルはnatモデルと比較して損失の上昇が極めて小さいことがわかる．これはPGD敵対的訓練によりモデルが頑健化され，損失関数の勾配が小さくなっているためと考えられる．

ヒートマップを見ると，どのサンプルも100反復以内に攻撃成功に至っておらず，全試行が最後まで正しく分類（黄色）されている．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_random}にCIFAR10 natモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_random_indices0-1-2-3-4_k100_eps0.03137254901960784_a0.00784313725490196_r20_seed0.png}
  \caption{CIFAR10 natモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像とPGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_random}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_random}より，CIFAR10ではMNISTと比較して誤分類が非常に高速であることがわかる．ほぼ全てのリスタートが数反復で攻撃成功に至っている．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_random}にCIFAR10 advモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_random_indices1-2-3-4-5_k100_eps0.03137254901960784_a0.00784313725490196_r20_seed0.png}
  \caption{CIFAR10 advモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像とPGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_random}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_random}より，MNIST advモデル同様に損失がほとんど上昇せず，100反復でも攻撃に成功しない場合が多いことがわかる．

% TODO: 推敲前
\subsection{DeepFool初期化}
\label{sec:deepfool_loss_curves}

本節では，DeepFool初期化PGD攻撃の損失曲線を可視化する．DeepFool初期化は決定的であるため，リスタート数は1であり，各パネルには1本の曲線のみが表示される．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_deepfool}にMNIST natモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_deepfool_indices0-1-2-3-4_k100_eps0.3_a0.01_r1_seed0_dfiter50_dfo0.02_dfj0.0_dfproject_clip.png}
  \caption{MNIST natモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_deepfool}
\end{figure}

\medskip
図\ref{fig:mnist_nat_deepfool}より，DeepFool初期化の効果が明確に確認できる．ヒートマップを見ると，反復0の時点で既に誤分類（紫色）に到達しており，DeepFoolにより決定境界を超えた状態からPGD攻撃が開始されていることがわかる．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_deepfool}にMNIST advモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_deepfool_indices0-1-2-3-4_k100_eps0.3_a0.01_r1_seed0_dfiter50_dfo0.02_dfj0.0_dfproject_clip.png}
  \caption{MNIST advモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_deepfool}
\end{figure}

\medskip
図\ref{fig:mnist_adv_deepfool}より，敵対的訓練されたadvモデルに対しては，DeepFool初期化を用いても100反復以内に誤分類を達成できていないことがわかる．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_deepfool}にCIFAR10 natモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_deepfool_indices0-1-2-3-4_k100_eps0.03137254901960784_a0.00784313725490196_r1_seed0_dfiter50_dfo0.02_dfj0.0_dfproject_clip.png}
  \caption{CIFAR10 natモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_deepfool}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_deepfool}より，CIFAR10 natモデルでもDeepFool初期化により反復0で既に誤分類を達成していることがわかる．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_deepfool}にCIFAR10 advモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_deepfool_indices1-2-3-4-5_k100_eps0.03137254901960784_a0.00784313725490196_r1_seed0_dfiter50_dfo0.02_dfj0.0_dfproject_clip.png}
  \caption{CIFAR10 advモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_deepfool}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_deepfool}より，CIFAR10 advモデルに対してはDeepFool初期化を用いても100反復以内に誤分類を達成できていないことがわかる．

\subsection{Multi-DeepFool初期化}
\label{sec:mdf_loss_curves}

本節では，Multi-DeepFool初期化PGD攻撃の損失曲線を可視化する．各パネルには9つのターゲットクラスに対応する9本の曲線が描かれている．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_mdf}にMNIST natモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_multi_deepfool_indices0-1-2-3-4_k100_eps0.3_a0.01_r9_seed0_dfiter50_dfo0.02.png}
  \caption{MNIST natモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_mdf}
\end{figure}

\medskip
図\ref{fig:mnist_nat_mdf}より，9つのターゲットクラスの多くで反復0〜1の時点で誤分類を達成していることがわかる．ターゲットクラスによって初期損失が異なり，決定境界までの距離の違いが反映されている．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_mdf}にMNIST advモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_multi_deepfool_indices0-1-2-3-4_k100_eps0.3_a0.01_r9_seed0_dfiter50_dfo0.02.png}
  \caption{MNIST advモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_mdf}
\end{figure}

\medskip
図\ref{fig:mnist_adv_mdf}より，敵対的訓練されたadvモデルでは，Multi-DeepFool初期化を用いても100反復以内に誤分類を達成できていないことがわかる．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_mdf}にCIFAR10 natモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_multi_deepfool_indices0-1-2-3-4_k100_eps0.03137254901960784_a0.00784313725490196_r9_seed0_dfiter50_dfo0.02.png}
  \caption{CIFAR10 natモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_mdf}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_mdf}より，CIFAR10 natモデルでは9つのターゲットクラスの全てで非常に高速に（反復0〜1で）誤分類を達成していることがわかる．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_mdf}にCIFAR10 advモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_multi_deepfool_indices1-2-3-4-5_k100_eps0.03137254901960784_a0.00784313725490196_r9_seed0_dfiter50_dfo0.02.png}
  \caption{CIFAR10 advモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復回数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool出力（制約適用前），PGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_mdf}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_mdf}より，CIFAR10 advモデルに対してはMulti-DeepFool初期化を用いても100反復以内に誤分類を達成できていないことがわかる．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{誤分類速度の定量分析}
\label{sec:misclassification_analysis}

本節では，第\ref{sec:misclassification_definition}節で定義した初回誤分類反復数を用いて，誤分類速度を定量的に分析する．全4モデル（nat, adv, nat\_and\_adv, weak\_adv）および全4初期化手法（クリーン，ランダム，DeepFool，Multi-DeepFool）の結果を比較する．

\subsection{MNIST}
\label{sec:mnist_misclassification}

図\ref{fig:mnist_misclassification_cdf}にMNISTにおける誤分類CDFを示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_misclassification_cdf_overlay.png}
  \caption{MNISTにおける誤分類CDF．横軸は反復回数，縦軸は誤分類したサンプルの累積割合．各線は初期化手法×モデルの組み合わせを表す．}
  \label{fig:mnist_misclassification_cdf}
\end{figure}

\paragraph{誤分類CDFの読み方}
誤分類CDFは，横軸に反復回数，縦軸にその反復回数までに誤分類を達成したサンプルの累積割合を示す．各曲線は初期化手法とモデルの組み合わせに対応している．曲線が左側にあるほど少ない反復回数で誤分類を達成しており，誤分類速度が速いことを意味する．曲線が縦軸の1.0に到達しない場合は，100反復以内に誤分類を達成できなかったサンプル（攻撃失敗）が存在することを示す．

図中の色は初期化手法を表し，青がクリーン初期化，緑がランダム初期化，赤がDeepFool初期化，オレンジがMulti-DeepFool初期化に対応する．線種とマーカーはモデルを表し，実線と丸マーカーがnatモデル，破線とダイヤモンドマーカーがweak\_advモデルに対応する．攻撃に失敗した組み合わせ（advモデルおよびnat\_and\_advモデル）はグレーで表示され，凡例に[FAILED]と記載されている．

\medskip
図\ref{fig:mnist_misclassification_cdf}より，以下の観察が得られる：
\begin{itemize}
    \item natモデルとweak\_advモデルのみが100反復以内に誤分類を達成している
    \item advモデルとnat\_and\_advモデルは，どの初期化手法を用いても100反復以内に誤分類を達成できていない
    \item DeepFool初期化では反復0で既に誤分類を達成している（CDFが反復0から立ち上がる）
    \item ランダム初期化ではnatモデルで平均6〜7反復，weak\_advモデルで平均25反復程度で誤分類を達成している
\end{itemize}

表\ref{table:mnist_misclassification}にMNISTにおける誤分類統計量を示す．

\begin{table}[hbtp]
  \caption{MNISTにおける誤分類統計}
  \label{table:mnist_misclassification}
  \centering
  \small
  \begin{tabular}{l|l|cccc}
    \hline
    & & & \multicolumn{3}{c}{初回誤分類反復数} \\
    \cline{4-6}
    モデル & 初期化 & 攻撃成功率 & 平均 & 中央値 & P95 \\
    \hline
    \multirow{4}{*}{nat} & clean & 100\% & 12.0 & 12.0 & 12.0 \\
    & random & 100\% & 6.6 & 7.0 & 8.0 \\
    & deepfool & 100\% & 0.0 & 0.0 & 0.0 \\
    & multi\_deepfool & 100\% & 0.7 & 1.0 & 1.0 \\
    \hline
    \multirow{4}{*}{nat\_and\_adv} & clean & 0\% & --- & --- & --- \\
    & random & 0\% & --- & --- & --- \\
    & deepfool & 0\% & --- & --- & --- \\
    & multi\_deepfool & 0\% & --- & --- & --- \\
    \hline
    \multirow{4}{*}{adv} & clean & 0\% & --- & --- & --- \\
    & random & 0\% & --- & --- & --- \\
    & deepfool & 0\% & --- & --- & --- \\
    & multi\_deepfool & 0\% & --- & --- & --- \\
    \hline
    \multirow{4}{*}{weak\_adv} & clean & 100\% & 35.0 & 35.0 & 35.0 \\
    & random & 100\% & 25.5 & 25.0 & 29.1 \\
    & deepfool & 100\% & 22.0 & 22.0 & 22.0 \\
    & multi\_deepfool & 100\% & 28.1 & 28.0 & 33.0 \\
    \hline
  \end{tabular}
\end{table}

表\ref{table:mnist_misclassification}より，以下の知見が得られる：
\begin{itemize}
    \item advモデルとnat\_and\_advモデルは全ての初期化手法で攻撃成功率0\%であり，100反復のPGD攻撃に対して堅牢である
    \item natモデルでは，DeepFool初期化が最も高速（反復0で誤分類）であり，次いでMulti-DeepFool初期化（平均0.7反復），ランダム初期化（平均6.6反復），クリーン初期化（平均12.0反復）の順である
    \item weak\_advモデルでは，DeepFool初期化（平均22.0反復）が最も高速だが，natモデルほどの差は見られない
\end{itemize}

\subsection{CIFAR10}
\label{sec:cifar10_misclassification}

図\ref{fig:cifar10_misclassification_cdf}にCIFAR10における誤分類CDFを示す．

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_misclassification_cdf_overlay.png}
  \caption{CIFAR10における誤分類CDF．横軸は反復回数，縦軸は誤分類したサンプルの累積割合．各線は初期化手法×モデルの組み合わせを表す．なお，同じ反復回数で誤分類を達成した曲線が重なるため，視認性のために横方向に微小なオフセットを加えて隣接させている．}
  \label{fig:cifar10_misclassification_cdf}
\end{figure}

\medskip
図\ref{fig:cifar10_misclassification_cdf}より，以下の観察が得られる：
\begin{itemize}
    \item advモデル以外の3モデル（nat, nat\_and\_adv, weak\_adv）が100反復以内に誤分類を達成している
    \item advモデルのみが，どの初期化手法を用いても100反復以内に誤分類を達成できていない
    \item 誤分類可能なモデルでは，MNISTより桁違いに高速に誤分類が達成されている（多くが2反復以内）
    \item DeepFool初期化およびMulti-DeepFool初期化では反復0で既に誤分類を達成しているケースが多い
\end{itemize}

表\ref{table:cifar10_misclassification}にCIFAR10における誤分類統計量を示す．

\begin{table}[hbtp]
  \caption{CIFAR10における誤分類統計}
  \label{table:cifar10_misclassification}
  \centering
  \small
  \begin{tabular}{l|l|cccc}
    \hline
    & & & \multicolumn{3}{c}{初回誤分類反復数} \\
    \cline{4-6}
    モデル & 初期化 & 攻撃成功率 & 平均 & 中央値 & P95 \\
    \hline
    \multirow{4}{*}{nat} & clean & 100\% & 1.0 & 1.0 & 1.0 \\
    & random & 100\% & 1.3 & 1.0 & 2.0 \\
    & deepfool & 100\% & 0.0 & 0.0 & 0.0 \\
    & multi\_deepfool & 100\% & 0.3 & 0.0 & 1.0 \\
    \hline
    \multirow{4}{*}{nat\_and\_adv} & clean & 100\% & 1.0 & 1.0 & 1.0 \\
    & random & 100\% & 1.0 & 1.0 & 1.0 \\
    & deepfool & 100\% & 0.0 & 0.0 & 0.0 \\
    & multi\_deepfool & 100\% & 0.0 & 0.0 & 0.0 \\
    \hline
    \multirow{4}{*}{adv} & clean & 0\% & --- & --- & --- \\
    & random & 0\% & --- & --- & --- \\
    & deepfool & 0\% & --- & --- & --- \\
    & multi\_deepfool & 0\% & --- & --- & --- \\
    \hline
    \multirow{4}{*}{weak\_adv} & clean & 100\% & 2.0 & 2.0 & 2.0 \\
    & random & 100\% & 2.0 & 2.0 & 2.0 \\
    & deepfool & 100\% & 1.0 & 1.0 & 1.0 \\
    & multi\_deepfool & 100\% & 0.1 & 0.0 & 0.6 \\
    \hline
  \end{tabular}
\end{table}

表\ref{table:cifar10_misclassification}より，以下の知見が得られる：
\begin{itemize}
    \item advモデルのみが全ての初期化手法で攻撃成功率0\%であり，100反復のPGD攻撃に対して堅牢である
    \item MNISTのnat\_and\_advモデルとは異なり，CIFAR10のnat\_and\_advモデルは容易に誤分類される
    \item 誤分類可能なモデルでは，全ての初期化手法で2反復以内に誤分類が達成されている
    \item DeepFool初期化およびMulti-DeepFool初期化では，反復0で既に誤分類を達成しているケースが多い（決定境界を超えた状態から攻撃開始）
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{総合考察}
\label{sec:discussion}

本節では，実験結果を総合的に考察する．

\subsection{Madryらの実験の再現性}
ランダム初期化PGD攻撃の損失曲線は，Madryらの報告と同様に，異なる初期点から開始しても同程度のプラトーに収束する傾向が確認された．これは，PGD攻撃が局所最適解に陥りにくく，初期点によらず同程度の損失に到達できることを示唆している．

\subsection{データセット間の比較}
CIFAR10はMNISTと比較して桁違いに高速な誤分類が観察された：
\begin{itemize}
    \item MNISTのnatモデル：ランダム初期化で平均6.6反復
    \item CIFAR10のnatモデル：ランダム初期化で平均1.3反復
\end{itemize}

この高速性の要因として，以下が考えられる：
\begin{itemize}
    \item \textbf{入力次元}：CIFAR10（$32 \times 32 \times 3 = 3072$次元）はMNIST（$28 \times 28 \times 1 = 784$次元）より高次元であり，攻撃可能な方向の自由度が高い
    \item \textbf{決定境界の複雑さ}：CIFAR10の画像がより複雑であり，決定境界が入力点から近い位置に存在する可能性がある
\end{itemize}

\subsection{モデル間の比較}
敵対的訓練の効果がMNISTとCIFAR10で異なる結果となった：
\begin{itemize}
    \item \textbf{MNIST}：advモデルとnat\_and\_advモデルは100反復でも誤分類せず，堅牢
    \item \textbf{CIFAR10}：advモデルのみが100反復でも誤分類せず，nat\_and\_advモデルは容易に誤分類
\end{itemize}

MNISTでnat\_and\_advモデルが堅牢でありながら，CIFAR10では脆弱である理由として，MNISTの方がより単純なタスクであり，クリーンデータと敵対的データの混合訓練でも十分な堅牢性が得られる可能性が考えられる．

\subsection{初期化手法の効果}
DeepFool初期化およびMulti-DeepFool初期化の効果は，モデルの堅牢性に強く依存する：
\begin{itemize}
    \item \textbf{脆弱なモデル（nat, weak\_adv）}：DeepFool初期化により反復0で誤分類を達成可能
    \item \textbf{堅牢なモデル（adv, MNIST nat\_and\_adv）}：どの初期化手法を用いても100反復以内に誤分類を達成できない
\end{itemize}

この結果は，DeepFool初期化の効果が「決定境界を超えた状態から攻撃を開始する」という性質に由来することを示唆している．堅牢なモデルでは，DeepFoolが$\ell_\infty$制約内で決定境界を超えることができないため，初期化手法の効果が発揮されない．

\subsection{実用上の示唆}
本実験結果から，PGD攻撃によるロバスト性評価について以下の示唆が得られた：
\begin{itemize}
    \item 堅牢なモデル（MNIST adv, nat\_and\_adv，CIFAR10 adv）に対しては，100反復のPGD攻撃でも誤分類を達成できない場合があり，より長い反復回数や他の攻撃手法の検討が必要
    \item 脆弱なモデルに対しては，DeepFool初期化を用いることで即座に誤分類を達成でき，反復回数を大幅に削減可能
    \item CIFAR10のような高次元データでは，誤分類が非常に高速に達成されるため，反復回数よりも攻撃の成否（攻撃成功率）が重要な指標となる
\end{itemize}
