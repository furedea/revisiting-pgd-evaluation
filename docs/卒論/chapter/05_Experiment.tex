\chapter{評価実験}
\label{chapter:experiment}
本章では，第\ref{chapter:introduction}章で述べた目的に基づき，第\ref{chapter:evaluation_method}章で定義した評価指標を用いて，PGD攻撃の誤分類性能を実験的に評価する．

\section{実験対象}
\label{sec:experiment_target}

本節では，本研究で使用するデータセット，初期化手法，およびモデルについて説明する．

\subsection{データセット}
\label{sec:datasets}

本研究では，画像分類の代表的なベンチマークデータセットであるMNISTとCIFAR10を使用する．これらはMadryらの実験\cite{PGD}で使用されたデータセットであり，実験の再現性を確保するために同じデータセットを採用した．表\ref{table:datasets}に両データセットの概要を示す．

\begin{table}[H]
  \caption{使用するデータセットの概要}
  \label{table:datasets}
  \centering
  \begin{tabular}{l|cc}
    \hline
    項目 & MNIST & CIFAR10 \\
    \hline
    画像サイズ & $28 \times 28 \times 1$ & $32 \times 32 \times 3$ \\
    訓練データ数 & 60,000 & 50,000 \\
    テストデータ数 & 10,000 & 10,000 \\
    ラベル数 & 10 & 10 \\
    内容 & 手書き数字 (0--9) & 物体画像 \\
    \hline
  \end{tabular}
\end{table}

MNISTは手書き数字（0から9）の画像データセットであり，機械学習の入門的なベンチマークとして広く用いられている．各画像は$28 \times 28$ピクセルのグレースケール画像であり，ピクセル値は$[0, 1]$に正規化されている．

CIFAR10は10種類の物体（飛行機，自動車，鳥，猫，鹿，犬，蛙，馬，船，トラック）の画像データセットである\cite{CIFAR10}．各画像は$32 \times 32$ピクセルの3チャネルカラー画像であり，MNISTと比較してより複雑な画像分類タスクを表現している．ラベルと物体の対応は以下の表\ref{table:CIFAR10}のようになる．

\begin{table}[H]
  \caption{CIFAR10のラベルと物体の対応}
  \label{table:CIFAR10}
  \centering
  \begin{tabular}{cccc}
    ラベル & 物体名 & ラベル & 物体名 \\
    \hline
    0 & airplane   & 5 & dog \\
    1 & automobile & 6 & frog \\
    2 & bird       & 7 & horse \\
    3 & cat        & 8 & ship \\
    4 & deer       & 9 & truck \\
    \hline
  \end{tabular}
\end{table}

\subsection{モデル}
\label{sec:target_models}

表\ref{table:models}に使用するモデルの詳細を示す．natおよびadvモデルは，Madryらが公開しているリポジトリ\cite{MadryMNIST, MadryCIFAR10}から入手した事前学習済みモデルである．ただし，advモデルはPGD攻撃に対して極めて頑強であり，100反復以内に誤分類が達成されなかったため，誤分類到達反復数の評価が困難であった．そこで，natとadvの中間的なロバスト性を持つと期待されるnat\_and\_advおよびweak\_advモデルを，同リポジトリのtrain.pyを修正して追加で学習させた．

\begin{table}[H]
  \caption{実験対象のモデル}
  \label{table:models}
  \centering
  \begin{tabular}{l|p{10cm}}
    \hline
    モデル名 & 訓練データ \\
    \hline
    nat & クリーンデータのみ \\
    adv & PGD敵対的サンプルのみ \\
    nat\_and\_adv & クリーンデータ50\%とPGD敵対的サンプル50\% \\
    weak\_adv & $\varepsilon$を半分にしたPGD敵対的サンプルのみ \\
    \hline
  \end{tabular}
\end{table}

各モデルの特性と，本研究での実験における意義は以下の通りである：
\begin{itemize}
    \item \textbf{nat（自然学習モデル）}：クリーンデータのみで訓練されたモデル．敵対的摂動に対して脆弱であり，PGD攻撃により高い損失に到達しやすい．誤分類が最も容易と予想され，ベースラインとして機能する．
    \item \textbf{adv（敵対的学習モデル）}：PGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．敵対的摂動に対して堅牢であり，損失の増加が抑制される傾向がある．誤分類が困難になる可能性があり，初期化手法の効果が顕著に現れると予想される．
    \item \textbf{nat\_and\_adv}：クリーンデータ50\%とPGD敵対的サンプル50\%を混合して訓練されたモデル．自然精度と敵対的精度の両立を目指した訓練方法であり，natとadvの中間的な特性を持つと予想される．
    \item \textbf{weak\_adv}：摂動制約$\varepsilon$を標準設定の半分にした弱いPGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．弱い攻撃に対しては堅牢だが，標準的な強さの攻撃に対する堅牢性は限定的．advよりは誤分類しやすいが，natよりは困難と予想される．
\end{itemize}

これらのモデル間での誤分類性能の違いを比較することで，モデルのロバスト性と誤分類到達反復数の関係を調査する．

\subsection{初期化手法}
\label{sec:init_methods}

PGD攻撃の初期点の選び方として，本研究では以下の初期化手法を比較する：
\begin{itemize}
    \item \textbf{クリーン初期化}：元の入力画像$x$をそのまま初期点として使用する．最も単純な初期化手法である．
    \item \textbf{ランダム初期化}：入力画像$x$を中心とする$\ell_\infty$制約範囲内から一様乱数で初期点を選択する．Madryらの論文\cite{PGD}で用いられた標準的な手法であり，ベースラインとして機能する．乱数シードを固定しており，実験の再現性が保証される．
    \item \textbf{DeepFool初期化}：DeepFoolで生成した敵対的サンプルを初期点とする．
    \item \textbf{Multi-DeepFool初期化}：各ターゲットラベルへのDeepFool結果を初期点とする．
\end{itemize}

ランダム初期化の詳細は第\ref{sec:random_init}節，DeepFool初期化およびMulti-DeepFool初期化の詳細は第\ref{chapter:proposed}章を参照されたい．

\section{実験設定}
\label{sec:experiment_setting}

\subsection{攻撃パラメータ}
表\ref{table:attack_params}にPGD攻撃のパラメータを示す．これらのパラメータはMadryらの論文\cite{PGD}と同一の設定である．DeepFoolのパラメータは，最大反復数$T_{\text{df}} = 50$，オーバーシュート係数$\eta = 0.02$とする．

\begin{table}[H]
  \caption{PGD攻撃のパラメータ設定}
  \label{table:attack_params}
  \centering
  \begin{tabular}{l|cc}
    \hline
    パラメータ & MNIST & CIFAR10 \\
    \hline
    摂動制約$\varepsilon$ & $0.3$ & $8/255 \approx 0.031$ \\
    ステップサイズ$\alpha$ & $0.01$ & $2/255 \approx 0.008$ \\
    反復数$T$ & $100$ & $100$ \\
    \hline
  \end{tabular}
\end{table}

\subsection{リスタート数}
表\ref{table:restart_per_init}に初期化手法ごとのリスタート数を示す．決定的な初期化手法（クリーン，DeepFool）はリスタート数1，確率的なランダム初期化はリスタート数20として実験を行う．ランダム初期化のリスタート数はMadryらの論文\cite{PGD}と同一の設定である．Multi-DeepFool初期化は9つのターゲットクラスに対して独立にPGD攻撃を実行するため，リスタート数を9として扱う．

\begin{table}[H]
  \caption{初期化手法ごとのリスタート数}
  \label{table:restart_per_init}
  \centering
  \begin{tabular}{l|c|l}
    \hline
    初期化手法 & リスタート数 & 性質 \\
    \hline
    クリーン & 1 & 決定的 \\
    ランダム & 20 & 確率的 \\
    DeepFool & 1 & 決定的 \\
    Multi-DeepFool & 9 & 決定的 \\
    \hline
  \end{tabular}
\end{table}

\subsection{テストサンプルの選択}
\label{sec:sample_selection}

テストデータの取得にはTensorFlowの標準データローダーを使用した．MNISTはTensorFlow 1.x系に付属するMNISTデータローダー，CIFAR10はKerasのデータセットAPIからそれぞれ取得した．これらのローダーが返すテストデータの順序は固定されており，再現性が保証される．

本研究では，損失曲線の観察（第\ref{sec:loss_curve_observation}節）と定量分析（第\ref{sec:misclassification_analysis}節）で異なるサンプル選択方法を用いる．いずれの場合も，PGD攻撃の前提条件である「元々正しく分類されているサンプルに対する攻撃」を満たすため，全てのモデル（nat, adv, nat\_and\_adv, weak\_adv）が自然画像の状態で正しく分類するサンプルのみを対象とする．

\subsubsection{損失曲線用サンプル}
\label{sec:sample_selection_loss_curve}

損失曲線の観察では，各初期化手法の挙動を定性的に観察することが目的である．テストデータを先頭から順に走査し，全モデルが正しく分類する最初の5枚を評価用サンプルとして使用する．

\subsubsection{定量分析用サンプル}
\label{sec:sample_selection_quantitative}

定量分析では，単一サンプルに依存しない一般的な傾向を把握することが目的である．特定のクラスに偏らないサンプル集合を得るため，各クラス（0〜9）から1枚ずつサンプルを選択する．具体的には，各クラスについてテストデータを先頭から順に走査し，全モデルが正しく分類する最初の1枚を選択する．これにより，計10枚のサンプルを得る．

定量分析では，各モデル・各初期化手法について以下の手順で結果を算出する：
\begin{enumerate}
    \item 10サンプルそれぞれに対してPGD攻撃をリスタート数分実行
    \item 各サンプルごとに，誤分類到達反復数の統計量（攻撃成功率，平均，中央値，P95など）および各反復時点で誤分類している試行の割合を算出
    \item 10サンプル分の結果を平均し，1つの代表値として使用
\end{enumerate}
統計量は表に，各反復時点での誤分類割合はヒートマップにそれぞれ示す．この方法により，特定のサンプルに依存しない，より一般的な傾向を把握できる．

\subsection{実行環境}
実験はPython 3.6.9およびTensorFlow 1.15.5を用いて実施した．Madryらが公開しているモデルおよび学習コードはTensorFlow 1.x系で実装されており，これらを正常に動作させるために環境を合わせた．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{損失曲線の観察}
\label{sec:loss_curve_observation}

本節では，各初期化手法によるPGD攻撃の損失曲線を可視化し，攻撃の挙動を定性的に観察する．これはMadryらの実験の再現及び拡張に相当する．なお，クリーン初期化は他の初期化手法との比較における基準として用いるため，本節では損失曲線を示さず，第\ref{sec:misclassification_analysis}節の定量分析においてのみ扱う．また，nat\_and\_advモデルおよびweak\_advモデルの損失曲線は付録\ref{appendix:loss_curves}に示す．

本節の図は行ごとに全て以下の3段構成となっている．また各列は，節\ref{sec:sample_selection}に基づき選択された，異なる5つのテストサンプルに対応している．

\paragraph{損失曲線（上段）}
縦軸は交差エントロピー損失（Cross-entropy Loss），横軸はPGD攻撃の反復数（PGD Iterations）を表す．反復0は初期状態に対応する．曲線が上昇するほど攻撃が進行（モデルの予測確信度が低下）していることを意味する．Multi-DeepFool初期化の図では，各曲線の色が境界までの距離の順位を表す．暖色（赤）はより近い境界へ向かった試行，寒色（青）はより遠い境界へ向かった試行を意味する．

\paragraph{正誤ヒートマップ（中段）}
縦軸は試行番号（Multi-DeepFool初期化では境界までの距離の順位），横軸は反復数を表す．各セルの色は，その時点での敵対的サンプルに対するモデルの予測結果を示す．黄色は正しく分類（攻撃失敗），紫色は誤分類（攻撃成功）を意味する．このヒートマップにより，各試行がいつ攻撃に成功したかを視覚的に確認できる．

\paragraph{画像比較（下段）}
左側の\texttt{x\_nat}は元の自然画像（摂動を加える前の入力），右側の\texttt{x\_adv}はPGD攻撃により生成された敵対的サンプルを示す．中央の\texttt{x\_init}はPGD攻撃の初期点を表し，初期化手法により以下の通り異なる：
\begin{itemize}
  \item \textbf{ランダム初期化}：$\ell_\infty$制約内のランダム摂動サンプル
  \item \textbf{DeepFool初期化}：$\ell_\infty$制約適用後のDeepFool敵対的サンプル
  \item \textbf{Multi-DeepFool初期化}：$\ell_\infty$制約適用後に損失が最大となる試行のDeepFool敵対的サンプル．ラベル中の\texttt{rank=X}は，そのサンプルが境界までの距離の順位でX番目のターゲットクラスに対応することを示す（0が最近傍）
\end{itemize}

\subsection{ランダム初期化}
\label{sec:random_loss_curves}

本節では，Madryらの実験の再現及び拡張として，各モデルに対するランダム初期化PGD攻撃の損失曲線と正誤ヒートマップを可視化する．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_random}にMNIST natモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_random.png}
  \caption{MNIST natモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，ランダム初期化サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_random}
\end{figure}

\medskip
図\ref{fig:mnist_nat_random}より，損失曲線を見ると，20回の試行は異なるランダム初期点から開始しているが，いずれも同程度の値に収束している．これはMadryらの「異なる初期点から開始しても同程度の局所最大解に収束する」という観察と一致する．ヒートマップを見ると，全5サンプルにおいて20回の試行全てが100反復以内に誤分類（紫色）を達成している．誤分類到達反復数はサンプルにより5〜15反復程度の幅がある．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_random}にMNIST advモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_random.png}
  \caption{MNIST advモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，ランダム初期化サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_random}
\end{figure}

\medskip
図\ref{fig:mnist_adv_random}より，損失曲線を見ると，advモデルはnatモデルと比較して損失の上昇値が極めて小さいことがわかる．また，natモデルでは初期の数反復で急激な損失上昇が見られたのに対し，advモデルではより緩やかな上昇にとどまり，収束せずに振動する試行も存在する．加えて試行毎に損失曲線の形状が大きく異なる．これはグラフの縦軸がnatモデルと比較して非常に狭い範囲に収まっていることから差が顕著に見えるからだと考えられる．ヒートマップを見ると，全5サンプルにおいて20回の試行全てが100反復以内に誤分類を達成できておらず，全ての試行が最後まで正しく分類（黄色）されている．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_random}にCIFAR10 natモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_random.png}
  \caption{CIFAR10 natモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，ランダム初期化サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_random}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_random}より，損失曲線を見ると，全試行が数反復で急速に収束している．ヒートマップを見ると，全5サンプルにおいて20回の試行全てが2反復以内に誤分類（紫色）を達成している．一部の試行では反復0（初期点）の時点で既に誤分類に到達している．MNISTと比較して誤分類到達が非常に高速である．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_random}にCIFAR10 advモデルに対するランダム初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_random.png}
  \caption{CIFAR10 advモデルに対するランダム初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なる試行）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，ランダム初期化サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_random}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_random}より，損失曲線を見ると，MNIST advモデルと比較して損失の上昇幅が大きい試行が存在する一方，ほとんど上昇しない試行も混在している．ヒートマップを見ると，サンプルによって結果が異なり，一部のサンプルでは複数の試行が誤分類を達成しているが，全く誤分類を達成できていないサンプルも存在する．

% TODO: 推敲前
\subsection{DeepFool初期化}
\label{sec:deepfool_loss_curves}

本節では，DeepFool初期化PGD攻撃の損失曲線を可視化する．DeepFool初期化は決定的であるため，リスタート数は1であり，各パネルには1本の曲線のみが表示される．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_deepfool}にMNIST natモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_deepfool.png}
  \caption{MNIST natモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_deepfool}
\end{figure}

\medskip
図\ref{fig:mnist_nat_deepfool}より，損失曲線を見ると，反復0で0付近から開始し，25〜50反復で40〜50程度の局所最大解に収束している．ヒートマップを見ると，全5サンプルで反復0の時点から誤分類（紫色）が達成されている．ランダム初期化（図\ref{fig:mnist_nat_random}）では5〜15反復程度で誤分類を達成していたのに対し，DeepFool初期化では反復0で既に誤分類を達成しており，初期点が決定境界を超えた状態であることがわかる．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_deepfool}にMNIST advモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_deepfool.png}
  \caption{MNIST advモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_deepfool}
\end{figure}

\medskip
図\ref{fig:mnist_adv_deepfool}より，損失曲線を見ると，全サンプルで損失値が$10^{-4}$〜$10^{-2}$程度と非常に小さい範囲に留まり，振動を伴いながら緩やかに上昇している．ヒートマップを見ると，全5サンプルで100反復を通して正しい分類（黄色）が維持されており，誤分類を達成できていない．ランダム初期化（図\ref{fig:mnist_adv_random}）と同様に，DeepFool初期化を用いてもadvモデルに対しては100反復以内に誤分類を達成できない．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_deepfool}にCIFAR10 natモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_deepfool.png}
  \caption{CIFAR10 natモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_deepfool}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_deepfool}より，損失曲線を見ると，反復0で0〜10程度から開始し，25反復程度で40〜60程度の局所最大解に収束している．ヒートマップを見ると，全5サンプルで反復0の時点から誤分類（紫色）が達成されている．ランダム初期化（図\ref{fig:cifar10_nat_random}）では2反復以内に誤分類を達成していたのに対し，DeepFool初期化では反復0で既に誤分類を達成している．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_deepfool}にCIFAR10 advモデルに対するDeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_deepfool.png}
  \caption{CIFAR10 advモデルに対するDeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，DeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_deepfool}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_deepfool}より，損失曲線を見ると，全サンプルで損失値が0〜10程度の範囲で緩やかに上昇している．ヒートマップを見ると，サンプルによって結果が異なり，100反復を通して正しい分類を維持するサンプルと，途中で誤分類を達成するサンプルが混在している．ランダム初期化（図\ref{fig:cifar10_adv_random}）と同様に，サンプルによって誤分類の可否が異なる結果となった．

\subsection{Multi-DeepFool初期化}
\label{sec:mdf_loss_curves}

本節では，Multi-DeepFool初期化PGD攻撃の損失曲線を可視化する．各パネルには9つのターゲットクラスに対応する9本の曲線が描かれている．

\subsubsection{MNIST natモデル}

図\ref{fig:mnist_nat_mdf}にMNIST natモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_nat_mdf.png}
  \caption{MNIST natモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，損失が最大となるDeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_nat_mdf}
\end{figure}

\medskip
図\ref{fig:mnist_nat_mdf}より，損失曲線を見ると，9本の曲線が反復0で0付近から開始し，50反復程度で30〜60程度の局所最大解に収束している．色（境界までの距離の順位）と収束損失の間には明確な傾向は見られない．ヒートマップを見ると，ほとんどの試行が反復0〜2の時点で誤分類（紫色）を達成している．ランダム初期化（図\ref{fig:mnist_nat_random}）では5〜15反復程度で誤分類を達成していたのに対し，Multi-DeepFool初期化ではほとんどの試行で反復0〜2で誤分類を達成している．

\subsubsection{MNIST advモデル}

図\ref{fig:mnist_adv_mdf}にMNIST advモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_adv_mdf.png}
  \caption{MNIST advモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，損失が最大となるDeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:mnist_adv_mdf}
\end{figure}

\medskip
図\ref{fig:mnist_adv_mdf}より，損失曲線を見ると，全サンプルで損失値が$10^{-5}$〜$10^{-2}$程度と非常に小さい範囲に留まり，振動を伴いながら緩やかに上昇している．ヒートマップを見ると，全5サンプルにおいて9つの試行全てが100反復を通して正しい分類（黄色）を維持しており，誤分類を達成できていない．ランダム初期化（図\ref{fig:mnist_adv_random}）と同様に，Multi-DeepFool初期化を用いてもadvモデルに対しては100反復以内に誤分類を達成できない．

\subsubsection{CIFAR10 natモデル}

図\ref{fig:cifar10_nat_mdf}にCIFAR10 natモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_nat_mdf.png}
  \caption{CIFAR10 natモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，損失が最大となるDeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_nat_mdf}
\end{figure}

\medskip
図\ref{fig:cifar10_nat_mdf}より，損失曲線を見ると，9本の曲線が反復0で0〜10程度から開始し，25反復程度で40〜60程度の局所最大解に収束している．ヒートマップを見ると，ほぼ全ての試行が反復0の時点で誤分類（紫色）を達成しており，一部の試行が反復1で誤分類を達成している．ランダム初期化（図\ref{fig:cifar10_nat_random}）では2反復以内に誤分類を達成していたのに対し，Multi-DeepFool初期化ではほぼ全ての試行で反復0〜1で誤分類を達成している．

\subsubsection{CIFAR10 advモデル}

図\ref{fig:cifar10_adv_mdf}にCIFAR10 advモデルに対するMulti-DeepFool初期化PGDの結果を示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_adv_mdf.png}
  \caption{CIFAR10 advモデルに対するMulti-DeepFool初期化PGD攻撃の結果．上段：損失曲線（横軸は反復数，縦軸は損失値，各線は異なるターゲットラベル）．中段：正誤ヒートマップ（黄色は正しい分類，紫色は誤分類）．下段：元画像，損失が最大となるDeepFool敵対的サンプル，PGD敵対的サンプルの比較．}
  \label{fig:cifar10_adv_mdf}
\end{figure}

\medskip
図\ref{fig:cifar10_adv_mdf}より，損失曲線を見ると，全サンプルで損失値が0〜10程度の範囲で緩やかに上昇している．ヒートマップを見ると，サンプルによって結果が大きく異なる．サンプル1, 3では全試行が100反復を通して正しい分類を維持しており，サンプル2, 4では全試行が誤分類を達成している．特にサンプル5では，境界までの距離が遠い試行（rank 5〜8）が途中で誤分類を達成する一方，境界までの距離が近い試行（rank 0〜4）の一部は100反復を通して正しい分類を維持するという特異な結果を示している．ランダム初期化（図\ref{fig:cifar10_adv_random}）と同様に，サンプルによって誤分類の可否が異なる結果となった．

\section{誤分類到達反復数の定量分析}
\label{sec:misclassification_analysis}

本節では，第\ref{sec:misclassification_definition}節で定義した誤分類到達反復数を用いて，PGD攻撃の誤分類性能を定量的に分析する．全4モデル（nat, adv, nat\_and\_adv, weak\_adv）および全4初期化手法（クリーン，ランダム，DeepFool，Multi-DeepFool）の結果を比較する．

第\ref{sec:sample_selection_quantitative}節で述べた通り，本節の分析では各クラスから1枚ずつ選択した計10サンプルを使用し，各サンプルの結果を平均して1つの代表値として扱う．

\subsection{MNIST}
\label{sec:mnist_misclassification}

図\ref{fig:mnist_misclassification_heatmap}にMNISTにおける誤分類ヒートマップを示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/mnist_misclassification_heatmap.png}
  \caption{MNISTにおける誤分類ヒートマップ．横軸はPGD反復数，縦軸はモデルと初期化手法の組み合わせ．色はその反復数時点で誤分類している試行の割合（10サンプル平均）を表す（緑：0\%，赤：100\%）．}
  \label{fig:mnist_misclassification_heatmap}
\end{figure}

\paragraph{誤分類ヒートマップの読み方}
誤分類ヒートマップは，横軸にPGD反復数（0〜100），縦軸にモデルと初期化手法の組み合わせを示す．各セルの色は，その反復数時点で誤分類している試行の割合（10サンプル平均）を表す．緑色は誤分類率0\%（全試行が正しく分類），赤色は誤分類率100\%（全試行が誤分類）を意味する．左側から赤くなるほど少ない反復数で誤分類を達成しており，100反復でも緑色のままの行は攻撃が失敗したことを示す．

\medskip
% TODO: 図の説明を実験結果に基づいて記述

表\ref{table:mnist_misclassification}にMNISTにおける誤分類統計量（10サンプル平均）を示す．

\begin{table}[H]
  \caption{MNISTにおける誤分類統計（10サンプル平均）}
  \label{table:mnist_misclassification}
  \centering
  \small
  \begin{tabular}{l|l|c|cccc}
    \hline
    & & & & \multicolumn{3}{c}{誤分類到達反復数} \\
    \cline{5-7}
    モデル & 初期化 & リスタート数 & 攻撃成功率 & 平均 & 中央値 & P95 \\
    \hline
    \multirow{4}{*}{nat} & clean & 1 & 100\% & 10.1 & 10.1 & 10.1 \\
     & random & 20 & 100\% & 5.6 & 5.7 & 6.8 \\
     & deepfool & 1 & 100\% & 0.1 & 0.1 & 0.1 \\
     & multi\_deepfool & 9 & 100\% & 0.5 & 0.5 & 0.9 \\
    \hline
    \multirow{4}{*}{nat\_and\_adv} & clean & 1 & 30\% & 25.0 & 25.0 & 25.0 \\
     & random & 20 & 7\% & 64.9 & 64.2 & 78.6 \\
     & deepfool & 1 & 50\% & 7.8 & 7.8 & 7.8 \\
     & multi\_deepfool & 9 & 30\% & 22.0 & 18.0 & 41.2 \\
    \hline
    \multirow{4}{*}{adv} & clean & 1 & 0\% & --- & --- & --- \\
     & random & 20 & 2\% & 38.0 & 34.0 & 63.7 \\
     & deepfool & 1 & 0\% & --- & --- & --- \\
     & multi\_deepfool & 9 & 0\% & --- & --- & --- \\
    \hline
    \multirow{4}{*}{weak\_adv} & clean & 1 & 90\% & 32.3 & 32.3 & 32.3 \\
     & random & 20 & 94\% & 25.2 & 24.9 & 31.9 \\
     & deepfool & 1 & 100\% & 20.7 & 20.7 & 20.7 \\
     & multi\_deepfool & 9 & 100\% & 26.6 & 26.1 & 34.6 \\
    \hline
  \end{tabular}
\end{table}


表\ref{table:mnist_misclassification}より，以下の知見が得られる：
\begin{itemize}
    \item advモデルとnat\_and\_advモデルは全ての初期化手法で攻撃成功率0\%であり，100反復のPGD攻撃に対して堅牢である
    \item natモデルでは，DeepFool初期化が最も高速（反復0で誤分類）であり，次いでMulti-DeepFool初期化（平均0.7反復），ランダム初期化（平均6.6反復），クリーン初期化（平均12.0反復）の順である
    \item weak\_advモデルでは，DeepFool初期化（平均22.0反復）が最も高速だが，natモデルほどの差は見られない
\end{itemize}

\subsection{CIFAR10}
\label{sec:cifar10_misclassification}

図\ref{fig:cifar10_misclassification_heatmap}にCIFAR10における誤分類ヒートマップを示す．ヒートマップの読み方は第\ref{sec:mnist_misclassification}節と同様である．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figure/cifar10_misclassification_heatmap.png}
  \caption{CIFAR10における誤分類ヒートマップ．横軸はPGD反復数，縦軸はモデルと初期化手法の組み合わせ．色はその反復数時点で誤分類している試行の割合（10サンプル平均）を表す（緑：0\%，赤：100\%）．}
  \label{fig:cifar10_misclassification_heatmap}
\end{figure}

\medskip
% TODO: 図の説明を実験結果に基づいて記述

表\ref{table:cifar10_misclassification}にCIFAR10における誤分類統計量（10サンプル平均）を示す．

\begin{table}[H]
  \caption{CIFAR10における誤分類統計（10サンプル平均）}
  \label{table:cifar10_misclassification}
  \centering
  \small
  \begin{tabular}{l|l|c|cccc}
    \hline
    & & & & \multicolumn{3}{c}{誤分類到達反復数} \\
    \cline{5-7}
    モデル & 初期化 & リスタート数 & 攻撃成功率 & 平均 & 中央値 & P95 \\
    \hline
    \multirow{4}{*}{nat} & clean & 1 & 100\% & 1.4 & 1.4 & 1.4 \\
     & random & 20 & 100\% & 1.3 & 1.2 & 1.6 \\
     & deepfool & 1 & 100\% & 0.1 & 0.1 & 0.1 \\
     & multi\_deepfool & 9 & 100\% & 0.3 & 0.2 & 0.8 \\
    \hline
    \multirow{4}{*}{nat\_and\_adv} & clean & 1 & 60\% & 3.8 & 3.8 & 3.8 \\
     & random & 20 & 60\% & 4.4 & 4.3 & 4.9 \\
     & deepfool & 1 & 60\% & 1.7 & 1.7 & 1.7 \\
     & multi\_deepfool & 9 & 60\% & 4.0 & 3.2 & 9.1 \\
    \hline
    \multirow{4}{*}{adv} & clean & 1 & 60\% & 4.7 & 4.7 & 4.7 \\
     & random & 20 & 57\% & 5.5 & 5.5 & 6.2 \\
     & deepfool & 1 & 50\% & 2.0 & 2.0 & 2.0 \\
     & multi\_deepfool & 9 & 58\% & 4.1 & 4.2 & 5.6 \\
    \hline
    \multirow{4}{*}{weak\_adv} & clean & 1 & 50\% & 4.8 & 4.8 & 4.8 \\
     & random & 20 & 50\% & 5.6 & 5.5 & 6.4 \\
     & deepfool & 1 & 40\% & 1.8 & 1.8 & 1.8 \\
     & multi\_deepfool & 9 & 51\% & 7.1 & 7.2 & 9.6 \\
    \hline
  \end{tabular}
\end{table}

表\ref{table:cifar10_misclassification}より，以下の知見が得られる：
\begin{itemize}
    \item advモデルのみが全ての初期化手法で攻撃成功率0\%であり，100反復のPGD攻撃に対して堅牢である
    \item MNISTのnat\_and\_advモデルとは異なり，CIFAR10のnat\_and\_advモデルは容易に誤分類される
    \item 誤分類可能なモデルでは，全ての初期化手法で2反復以内に誤分類が達成されている
    \item DeepFool初期化およびMulti-DeepFool初期化では，反復0で既に誤分類を達成しているケースが多い（決定境界を超えた状態から攻撃開始）
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{総合考察}
\label{sec:discussion}

本節では，損失曲線の観察（第\ref{sec:loss_curve_observation}節）および誤分類到達反復数の定量分析（第\ref{sec:misclassification_analysis}節）の結果を総合的に考察する．

\subsection{Madryらの実験の再現性}
ランダム初期化PGD攻撃において，Madryらが報告した「異なる初期点から開始しても同程度の局所最大解に収束する」という観察が再現された．損失曲線（図\ref{fig:mnist_nat_random}，\ref{fig:cifar10_nat_random}）では，20回の試行が異なる初期点から開始しているにもかかわらず，いずれも同程度の損失値に収束している．また，正誤ヒートマップにおいても，natモデルでは全ての試行が誤分類を達成しており，初期点の選択が攻撃成功率に大きな影響を与えないことが確認された．

\subsection{データセット間の比較}
CIFAR10はMNISTと比較して桁違いに高速な誤分類が観察された．表\ref{table:mnist_misclassification}および表\ref{table:cifar10_misclassification}より：
\begin{itemize}
    \item MNISTのnatモデル：ランダム初期化で平均6.6反復，クリーン初期化で平均12.0反復
    \item CIFAR10のnatモデル：ランダム初期化で平均1.3反復，クリーン初期化で平均1.0反復
\end{itemize}

CIFAR10では，natモデルに対してランダム初期化の一部の試行で反復0（初期点）の時点で既に誤分類が達成されている（図\ref{fig:cifar10_nat_random}）．この高速性の要因として，CIFAR10（$32 \times 32 \times 3 = 3072$次元）がMNIST（$28 \times 28 \times 1 = 784$次元）より高次元であり，攻撃可能な方向の自由度が高いこと，および決定境界が入力点から近い位置に存在することが考えられる．

\subsection{モデル間の比較}
敵対的訓練の効果がMNISTとCIFAR10で大きく異なる結果となった：
\begin{itemize}
    \item \textbf{MNIST}：advモデルとnat\_and\_advモデルは，全ての初期化手法で攻撃成功率0\%（100反復でも誤分類を達成せず堅牢）
    \item \textbf{CIFAR10}：advモデルのみが攻撃成功率0\%で堅牢．nat\_and\_advモデルは全ての初期化手法で攻撃成功率100\%であり，平均0〜1反復で誤分類を達成
\end{itemize}

weak\_advモデルは両データセットで誤分類を達成されたが，MNISTでは平均22〜35反復を要するのに対し，CIFAR10では平均0.1〜2反復と高速であった．nat\_and\_advモデルがMNISTでは堅牢でCIFAR10では脆弱である理由として，MNISTの方がより単純なタスクであり，クリーンデータと敵対的データの混合訓練でも十分な堅牢性が得られる可能性が考えられる．

\subsection{初期化手法の効果}
初期化手法の効果は，モデルの堅牢性に強く依存する：
\begin{itemize}
    \item \textbf{脆弱なモデル（nat, CIFAR10 nat\_and\_adv, weak\_adv）}：DeepFool初期化およびMulti-DeepFool初期化により反復0〜1で誤分類を達成可能．MNISTのnatモデルでは，DeepFool初期化（平均0反復）とMulti-DeepFool初期化（平均0.7反復）がランダム初期化（平均6.6反復）より大幅に高速．CIFAR10のweak\_advモデルでは，Multi-DeepFool初期化（平均0.1反復）がDeepFool初期化（平均1反復）より高速であった
    \item \textbf{堅牢なモデル（adv, MNIST nat\_and\_adv）}：どの初期化手法を用いても100反復以内に誤分類を達成できない．損失曲線（図\ref{fig:mnist_adv_random}，\ref{fig:mnist_adv_deepfool}，\ref{fig:mnist_adv_mdf}）でも損失値は$10^{-5}$〜$10^{-2}$程度と非常に小さい範囲に留まる
\end{itemize}

DeepFool初期化およびMulti-DeepFool初期化の効果は「$\ell_\infty$制約内で決定境界を超えた状態から攻撃を開始する」という性質に由来する．堅牢なモデルでは，DeepFoolが$\ell_\infty$制約内で決定境界を超えることができないため，初期化手法の効果が発揮されない．CIFAR10 advモデルに対するMulti-DeepFool初期化（図\ref{fig:cifar10_adv_mdf}）では，サンプル2, 4では全試行が誤分類を達成する一方，サンプル1, 3では全試行が正分類を維持し，サンプル5では境界までの距離が遠い試行（rank 5〜8）が誤分類を達成し近い試行（rank 0〜4）の一部が正分類を維持するという特異な結果となった．これはモデルの局所的な堅牢性の不均一さを示唆している．

\subsection{実用上の示唆}
本実験結果から，PGD攻撃によるロバスト性評価について以下の示唆が得られた：
\begin{itemize}
    \item 堅牢なモデル（MNIST adv, nat\_and\_adv，CIFAR10 adv）に対しては，100反復のPGD攻撃でも誤分類を達成できない．より長い反復数や他の攻撃手法の検討が必要である
    \item CIFAR10のような高次元データでは，誤分類が2反復以内に達成されるため，反復数よりも攻撃の成否（攻撃成功率）が重要な指標となる
    \item 脆弱なモデルに対しては，DeepFool初期化を用いることで反復0で誤分類を達成でき，誤分類到達反復数のみを評価する場合は有効な初期化手法である
    \item Multi-DeepFool初期化はPGDの反復数が50回未満で済む場合はランダム初期化（9回リスタート）と比較して計算コストが低くなる（付録\ref{appendix:computational_cost}参照）．条件を満たす場合，脆弱なモデルにおいて誤分類が達成される場合に誤分類到達反復数，計算コスト両面で他の手法に比べ有効であり，DeepFoolと比べて約クラス数分の多様な探索が可能な点も評価できる
    \item CIFAR10 advモデルでは，サンプルによって攻撃の成否が異なるため，ロバスト性評価には複数サンプルでの検証が重要である
\end{itemize}
