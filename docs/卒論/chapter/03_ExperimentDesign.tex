\chapter{実験設計}
\label{chapter:experiment_design}
本章では，本研究における実験の目的，実験対象，および収束性を定量的に評価するための方法について述べる．

\section{本研究における実験の目的}
\label{sec:experiment_purpose}

Madryらは\cite{PGD}において，PGD攻撃の損失曲線が複数のランダム初期点から開始しても同程度の局所最大解に収束することを可視化により示した．しかし，この検証は定性的なものであり，具体的にどの反復回数で収束が起こるか，あるいは収束の速さがモデルや初期化手法によってどのように異なるかについては詳細に論じられていない．

本研究では，Madryらの実験を定量的に拡張し，以下の観点から実験を行う：
\begin{itemize}
    \item 損失曲線が収束に達するまでの反復回数の統計的分布
    \item 異なるモデル間での収束挙動の比較
    \item 異なる初期化手法が収束速度に与える影響
\end{itemize}

\section{実験対象}
\label{sec:experiment_target}

本節では，本研究で使用するデータセット，初期化手法，およびモデルについて説明する．

\subsection{データセット}
\label{sec:datasets}

本研究では，画像分類の代表的なベンチマークデータセットであるMNISTとCIFAR10を使用する．表\ref{table:datasets}に両データセットの概要を示す．

\begin{table}[hbtp]
  \caption{使用するデータセットの概要}
  \label{table:datasets}
  \centering
  \begin{tabular}{l|cc}
    \hline
    項目 & MNIST & CIFAR10 \\
    \hline
    画像サイズ & $28 \times 28 \times 1$ & $32 \times 32 \times 3$ \\
    訓練データ数 & 60,000 & 50,000 \\
    テストデータ数 & 10,000 & 10,000 \\
    ラベル数 & 10 & 10 \\
    内容 & 手書き数字 (0--9) & 物体画像 \\
    \hline
  \end{tabular}
\end{table}

MNISTは手書き数字（0から9）の画像データセットであり，機械学習の入門的なベンチマークとして広く用いられている．各画像は$28 \times 28$ピクセルのグレースケール画像であり，ピクセル値は$[0, 1]$に正規化されている．

CIFAR10は10種類の物体（飛行機，自動車，鳥，猫，鹿，犬，蛙，馬，船，トラック）の画像データセットである\cite{CIFAR10}．各画像は$32 \times 32$ピクセルの3チャネルカラー画像であり，MNISTと比較してより複雑な画像分類タスクを表現している．

\subsection{初期化手法}
\label{sec:init_methods}

PGD攻撃の初期点の選び方として，本研究では以下の初期化手法を比較する：
\begin{itemize}
    \item \textbf{ランダム初期化}：入力画像$x$を中心とする$\ell_\infty$制約範囲内から一様乱数で初期点を選択する．Madryらの論文\cite{PGD}で用いられた標準的な手法であり，ベースラインとして機能する．
\end{itemize}

これに加え，第\ref{chapter:proposed}章で提案するDeepFool初期化およびMulti-DeepFool初期化についても実験を行う．

\subsection{モデル}
\label{sec:target_models}

表\ref{table:models}に使用するモデルの詳細を示す．natおよびadvモデルは，Madryらが公開しているリポジトリ\cite{MadryMNIST, MadryCIFAR10}から入手した事前学習済みモデルである．nat\_and\_advおよびweak\_advモデルは，同リポジトリのtrain.pyを修正し，訓練データの構成を変更して学習させたモデルである．

\begin{table}[hbtp]
  \caption{実験対象のモデル}
  \label{table:models}
  \centering
  \begin{tabular}{l|p{10cm}}
    \hline
    モデル名 & 訓練データ \\
    \hline
    nat & クリーンデータのみ \\
    adv & PGD敵対的サンプルのみ \\
    nat\_and\_adv & クリーンデータ50\%とPGD敵対的サンプル50\% \\
    weak\_adv & $\varepsilon$を半分にしたPGD敵対的サンプルのみ \\
    \hline
  \end{tabular}
\end{table}

各モデルの特性と，本研究での実験における意義は以下の通りである：
\begin{itemize}
    \item \textbf{nat（自然学習モデル）}：クリーンデータのみで訓練されたモデル．敵対的摂動に対して脆弱であり，PGD攻撃により高い損失に到達しやすい．収束が最も容易と予想され，ベースラインとして機能する．
    \item \textbf{adv（敵対的学習モデル）}：PGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．敵対的摂動に対して堅牢であり，損失の増加が抑制される傾向がある．収束が困難になる可能性があり，初期化手法の効果が顕著に現れると予想される．
    \item \textbf{nat\_and\_adv}：クリーンデータ50\%とPGD敵対的サンプル50\%を混合して訓練されたモデル．自然精度と敵対的精度の両立を目指した訓練方法であり，natとadvの中間的な特性を持つと予想される．
    \item \textbf{weak\_adv}：摂動制約$\varepsilon$を標準設定の半分にした弱いPGD攻撃で生成した敵対的サンプルのみで訓練されたモデル．弱い攻撃に対しては堅牢だが，標準的な強さの攻撃に対する堅牢性は限定的．advよりは収束しやすいが，natよりは困難と予想される．
\end{itemize}

これらのモデル間での収束挙動の違いを比較することで，モデルのロバスト性と収束特性の関係を調査する．

\section{収束の定義}
\label{sec:convergence_definition}

PGD攻撃の収束を定量的に評価するためには，「収束」を明確に定義する必要がある．本節では，正規化損失進捗率と収束閾値という2つの概念を導入し，収束の定量的な定義を与える．

\subsection{正規化損失進捗率の定義}
\label{sec:normalized_loss_progress_ratio}

PGD攻撃における損失の絶対値は，モデルやデータセットによって大きく異なる．例えば，自然学習モデルでは損失が大きく増加しやすい一方，敵対的学習モデルでは損失の増加が抑制される．このため，異なる条件間で収束の進捗度を直接比較することは困難である．

この問題を解決するため，本研究では\textbf{正規化損失進捗率}（normalized loss progress ratio）を導入する．この指標は損失を0〜1の範囲に正規化することで，異なるモデルやデータセット間での収束進捗の統一的な比較を可能にする．

$t$回目の反復における損失を$L_t$，初期損失を$L_0$，全反復における最大損失を$L_{\max} = \max_{0 \leq t \leq T} L_t$とすると，正規化損失進捗率$\rho_t$は式(\ref{eq:normalized_loss_progress_ratio})で定義する．
\begin{align}
    \rho_t = \frac{L_t - L_0}{L_{\max} - L_0}
    \label{eq:normalized_loss_progress_ratio}
\end{align}

この定義により，以下の性質が成り立つ：
\begin{itemize}
    \item $\rho_0 = 0$：初期時点では進捗率は0である
    \item $\rho_{t^*} = 1$：最大損失に到達した時点$t^*$で進捗率は1となる
    \item $0 \leq \rho_t \leq 1$：進捗率は常に0から1の範囲に収まる
\end{itemize}

これにより，損失の絶対値が大きく異なるモデルやデータセット間でも，「最大損失に対してどの程度進んだか」という観点で統一的な比較が可能となる．

\subsection{収束閾値と収束反復数}
\label{sec:convergence_threshold}

正規化損失進捗率は各時点での進捗度を表すが，「いつ収束したか」を判定するためには追加の基準が必要である．本研究では，\textbf{収束閾値}$\theta$を導入し，正規化損失進捗率が閾値に達した時点を収束とみなす．

収束閾値$\theta \in (0, 1)$を用いて，正規化損失進捗率が初めて閾値に達した反復回数を\textbf{収束反復数}と定義する．すなわち，収束反復数$t^*$は式(\ref{eq:convergence_iteration})で定義する．
\begin{align}
    t^* = \min\{t : \rho_t \geq \theta\}
    \label{eq:convergence_iteration}
\end{align}

本研究では，収束閾値として$\theta = 0.90$を採用する．これは，最大損失の90\%に到達した時点を収束とみなすことを意味する．この閾値は，損失曲線が局所最大解に達する直前の段階を捉えるものとして選択した．

さらに，閾値到達後の安定性を考慮するため，\textbf{安定性条件}を導入する．安定性条件とは，閾値$\theta$に到達した後，最終$W$反復（本研究では$W=10$）の間その閾値以上を維持することを要求する条件である．これにより，一時的に閾値に到達しただけで再び下回るような不安定な収束を除外できる．

したがって，本研究における「収束」の判定基準は以下の2条件を満たすこととする：
\begin{enumerate}
    \item 閾値到達条件：正規化損失進捗率が閾値$\theta$に到達する
    \item 安定性条件：最終$W$反復の間，閾値$\theta$以上を維持する
\end{enumerate}

\subsection{非収束の分類}
\label{sec:non_convergence_types}

全ての試行が収束閾値に到達するとは限らない．特に，敵対的学習モデルに対する攻撃や，特定の初期化手法を用いた場合には，収束に失敗するケースが存在する．このような非収束ケースを適切に分類することは，収束失敗の原因を理解し，初期化手法やモデルの特性を評価する上で重要である．

本研究では，試行が収束閾値に到達しない場合を以下の2種類に分類する：
\begin{itemize}
    \item \textbf{NR（Never Reached）}：全反復を通じて一度も閾値$\theta$に到達しなかった場合．これは，PGD攻撃が十分な損失増加を達成できなかったことを意味する．敵対的学習により堅牢なモデルや，初期点が不適切な場合に発生しやすい．
    \item \textbf{US（Unstable）}：閾値$\theta$に到達したが，最終$W$反復（本研究では$W=10$）の間に閾値を維持できなかった場合．これは，損失が一度は閾値に到達したものの，その後の反復で損失が減少し閾値を下回った不安定なケースを表す．
\end{itemize}

USが発生する典型的な状況は，損失曲線が閾値付近で振動する場合である．これは，PGD攻撃の勾配上昇が局所的な最大値に到達した後，ステップサイズの影響で最大値を超えて損失が減少するケースで起こりうる．NRとUSを区別することで，収束失敗の原因が「そもそも閾値に到達できない」からなのか，「到達後に維持できない」からなのかを切り分けることができる．

\section{評価指標}
\label{sec:evaluation_metrics}

収束の定量的評価のため，以下の指標を用いる．

\subsection{収束率}
\label{sec:convergence_rate}

収束率は，与えられた反復回数内で収束閾値に到達した試行の割合を表す．総試行数を$N$，反復回数$T$以内に収束した試行数を$N_c$とすると，収束率$R_c$は式(\ref{eq:convergence_rate})で定義する．
\begin{align}
    R_c = \frac{N_c}{N}
    \label{eq:convergence_rate}
\end{align}

本研究では最大反復回数$T = 100$を設定している．$R_c = 1.0$であれば全試行が100反復以内に収束閾値に到達したことを意味し，$R_c < 1.0$の場合は一部の試行で収束が失敗（NRまたはUS）したことを示す．

\subsection{収束反復数の統計量}
\label{sec:convergence_statistics}

収束率は全体的な成功率を示すが，収束に要した反復回数の分布については情報を与えない．そこで，収束反復数の分布を特徴づけるため，以下の統計量を計算する：
\begin{itemize}
    \item \textbf{平均収束反復数}：収束反復数の算術平均．全体的な収束速度の目安となる．
    \item \textbf{中央値（Median）}：収束反復数の中央値．外れ値の影響を受けにくく，典型的な収束速度を表す．
    \item \textbf{95パーセンタイル（P95）}：収束反復数の分布において95\%の試行が収束に到達する反復回数．最悪ケースに近い収束速度の目安となる．
\end{itemize}

これらの統計量を組み合わせることで，収束速度の分布を多面的に把握できる．例えば，平均と中央値が大きく異なる場合は，一部の試行で収束が著しく遅いことを示唆する．P95は，ほぼ全ての試行が収束に到達するために必要な反復回数の実用的な目安として重要である．

\subsection{累積分布関数（CDF）による可視化}
\label{sec:cdf}

収束反復数の分布を可視化するため，累積分布関数（Cumulative Distribution Function; CDF）を用いる．CDFは，ある反復回数$t$までに収束した試行の割合を表す．

CDFが急激に立ち上がる場合は多くの試行が短い反復回数で収束していることを示し，緩やかに立ち上がる場合は収束に要する反復回数のばらつきが大きいことを示す．
